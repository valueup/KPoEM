{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wqz4Tfmc8OKk"
   },
   "source": [
    "# KcELECTRA + KOTE + KPoEM v3 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The datasets used\n",
    "  - KOTE (Korean Online That-gul Emotions) Dataset: https://github.com/searle-j/KOTE\n",
    "  - KPoEM (Korean Poetry Emotion Mapping) Dataset v3: https://zenodo.org/records/15572285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W287pi6VS4yk"
   },
   "source": [
    "## 1. Basic setup and library imports\n",
    "- Import Libraries and Set Configuration\n",
    "  - Installs and imports required libraries (e.g., optuna, pytorch_lightning, transformers, etc.).\n",
    "  - Sets random seed for reproducibility and configures model/data directories.\n",
    "  - Defines constants such as number of epochs and input max length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "99k4AIQuS4yU",
    "outputId": "7d7b4288-3df3-44cd-a8b0-8dfbc70a30df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.29.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.10.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (8.4.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.23.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.13)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.36.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (4.3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.4)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.16.5)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython>=4.0.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython>=4.0.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data->ipython>=4.0.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.6.0)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1. 기본 설정 및 라이브러리 임포트\n",
    "# ===================================================================\n",
    "!pip install -q optuna\n",
    "!pip install ipywidgets\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, precision_score, recall_score\n",
    "from torchmetrics.functional.classification import multilabel_accuracy\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch Lightning 로그 줄이기\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "# 시드 고정 및 환경 설정\n",
    "RANDOM_SEED = 42\n",
    "pl.seed_everything(RANDOM_SEED, workers=True)\n",
    "torch.set_float32_matmul_precision('medium') # A100 등 TensorCore 사용 시 성능 향상\n",
    "\n",
    "# 경로 설정\n",
    "DATA_DIR = '../data/'        # 상황에 맞게 조정\n",
    "MODEL_SAVE_DIR = './model/'  # 상황에 맞게 조정\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 학습 상수 설정\n",
    "N_EPOCHS_OPTUNA = 3    # Optuna 탐색 시 사용할 Epochs\n",
    "N_EPOCHS_TRAIN = 10    # 본 학습 시 사용할 Epochs\n",
    "THRESHOLD = 0.3        # 고정 임계값\n",
    "MAX_LENGTH = 512       # 토크나이저 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading KPoEM_line_dataset_v3.tsv ...\n",
      "다운로드 완료: ../data/KPoEM_line_dataset_v3.tsv\n",
      "Downloading KPoEM_poem_dataset_v3.tsv ...\n",
      "다운로드 완료: ../data/KPoEM_poem_dataset_v3.tsv\n",
      "Downloading from GitHub: train.tsv\n",
      "완료: ../data/train.tsv\n",
      "Downloading from GitHub: val.tsv\n",
      "완료: ../data/val.tsv\n",
      "Downloading from GitHub: test.tsv\n",
      "완료: ../data/test.tsv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Zenodo에서 KPoEM 데이터 다운로드\n",
    "# ============================\n",
    "\n",
    "# 다운로드 URL 설정\n",
    "file_names = [\n",
    "    'KPoEM_line_dataset_v3.tsv',\n",
    "    'KPoEM_poem_dataset_v3.tsv'\n",
    "]\n",
    "zenodo_record_id = '15572285'\n",
    "\n",
    "# KPoEM line, poem 데이터셋 다운로드\n",
    "for file_name in file_names:\n",
    "    download_url = f'https://zenodo.org/records/{zenodo_record_id}/files/{file_name}?download=1'\n",
    "    save_path = os.path.join(DATA_DIR, file_name)\n",
    "    \n",
    "    print(f\"Downloading {file_name} ...\")\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"다운로드 완료: {save_path}\")\n",
    "    else:\n",
    "        print(f\"다운로드 실패: {file_name} (status code: {response.status_code})\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# GitHub에서 KOTE 데이터 다운로드\n",
    "# ============================\n",
    "\n",
    "# 다운로드 URL 설정\n",
    "github_base_url = 'https://raw.githubusercontent.com/searle-j/KOTE/main/'\n",
    "github_file_names = ['train.tsv', 'val.tsv', 'test.tsv']\n",
    "\n",
    "# KOTE train, val, test 데이터셋 다운로드\n",
    "for file_name in github_file_names:\n",
    "    download_url = github_base_url + file_name\n",
    "    save_path = os.path.join(DATA_DIR, file_name)\n",
    "    \n",
    "    print(f\"Downloading from GitHub: {file_name}\")\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"완료: {save_path}\")\n",
    "    else:\n",
    "        print(f\"실패: {file_name} (status code: {response.status_code})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMm-BUtIkNoj"
   },
   "source": [
    "## 2. Data preparation (loading, preprocessing, splitting)\n",
    "- Define Labels and Preprocessing Functions\n",
    "  - Declares `LABELS`, a list of 44 Korean emotion categories.\n",
    "  - `preprocess_by_paper_method()`: For KPoEM, aggregates labels from 5 annotators, applies min-max scaling to label agreement counts, and binarizes using a threshold.\n",
    "  - `preprocess_kote()`: For KOTE, parses label indices from string to list and one-hot encodes them.\n",
    "- Load and Split Datasets\n",
    "  - Loads line-level and poem-level KPoEM data (`*.tsv` files), applies preprocessing, and splits into train/val/test sets.\n",
    "  - Loads KOTE train/val/test splits, preprocesses them, and filters out rows with no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dHyqmDAuS4yk",
    "outputId": "385cc4b2-f1b3-488d-b2b4-a94a7172b863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> KPoEM 데이터셋 준비 중...\n",
      "KPoEM 데이터셋: Train 6096, Val 763, Test 763\n",
      "\n",
      ">>> KOTE 데이터셋 준비 중 (로컬 tsv 파일 로드)...\n",
      "KOTE 데이터셋 로드 및 전처리 완료: Train 40000, Val 5000, Test 5000\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 2. 데이터 준비 (로드, 전처리, 분할) - KOTE 형식 반영 최종 수정\n",
    "# ===================================================================\n",
    "\n",
    "# 2.1. 공통 전처리 함수 및 라벨 정의\n",
    "LABELS = ['불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경', '기대감', '우쭐댐/무시함', '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적', '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망', '한심함', '역겨움/징그러움', '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음', '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움', '재미없음', '불쌍함/연민', '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰']\n",
    "\n",
    "def preprocess_by_paper_method(df: pd.DataFrame, threshold: float = 0.2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    KPoEM 데이터에 논문의 처리 방식을 적용\n",
    "    1. 모든 평가자의 라벨을 취합\n",
    "    2. 각 라벨의 등장 횟수(0~5)를 '점수'로 사용\n",
    "    3. 점수를 Min-Max 스케일링하고 임계값을 적용해 최종 라벨 벡터를 생성\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 모든 평가자의 라벨 취합\n",
    "    # 각 행(댓글)에 대해 5명 평가자의 모든 감정 라벨을 하나의 리스트로 합침\n",
    "    label_lists = []\n",
    "    annotator_cols = [f'annotator0{i}' for i in range(1, 6) if f'annotator0{i}' in df.columns]\n",
    "    if not annotator_cols: raise ValueError(\"KPoEM 데이터에 annotator 컬럼이 없습니다.\")\n",
    "    for idx, row in df.iterrows():\n",
    "        all_labels = []\n",
    "        for col in annotator_cols: all_labels.extend(str(row[col]).split(','))\n",
    "        label_lists.append([label.strip() for label in all_labels if label])\n",
    "\n",
    "    # 2. '동의 횟수'를 '점수'로 변환\n",
    "    # 각 행별로 44개 감정에 대해 등장 횟수를 계산하여 점수 벡터(0~5점)를 생성\n",
    "    score_vectors = [[Counter(comment_labels).get(label, 0) for label in LABELS] for comment_labels in label_lists]\n",
    "    scores = np.array(score_vectors, dtype=float)\n",
    "\n",
    "    # 3. Min-Max 스케일링 및 이진화 (KOTE 논문 방식)\n",
    "    min_scores, max_scores = scores.min(axis=1, keepdims=True), scores.max(axis=1, keepdims=True)\n",
    "    numerator = scores - min_scores\n",
    "    denominator = max_scores - min_scores\n",
    "    scaled_scores = np.where(denominator != 0, numerator / denominator, 0)\n",
    "    df['label_vector'] = [list(row) for row in (scaled_scores > threshold).astype(int)]\n",
    "    return df\n",
    "\n",
    "# KOTE 전용 함수\n",
    "def indices_to_vector(indices_data):\n",
    "    vec = [0] * len(LABELS)\n",
    "\n",
    "    # 입력 데이터가 단일 숫자인지 확인하고, 맞으면 리스트로 감싸기\n",
    "    if isinstance(indices_data, int):\n",
    "        indices_list = [indices_data]\n",
    "    else:\n",
    "        indices_list = indices_data\n",
    "\n",
    "    # indices_list는 항상 리스트이므로 에러 없이 반복 가능\n",
    "    if indices_list: # 리스트가 비어있지 않은 경우에만 실행\n",
    "        for idx in indices_list:\n",
    "            if 0 <= idx < len(LABELS):\n",
    "                vec[idx] = 1\n",
    "    return vec\n",
    "\n",
    "def preprocess_kote(df):\n",
    "    df['label_indices'] = df['labels'].apply(ast.literal_eval)         # 'labels' 컬럼의 문자열(예: \"[5, 8]\")을 실제 리스트(예: [5, 8])로 변환\n",
    "    df['label_vector'] = df['label_indices'].apply(indices_to_vector)  # 인덱스 리스트를 원-핫 인코딩 벡터로 변환\n",
    "    df = df[df['label_vector'].apply(sum) > 0].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2.2. KPoEM 데이터 로드 및 분할\n",
    "print(\">>> KPoEM 데이터셋 준비 중...\")\n",
    "try:\n",
    "    line_df = pd.read_csv(os.path.join(DATA_DIR, \"KPoEM_line_dataset_v3.tsv\"), sep='\\t')\n",
    "    poem_df = pd.read_csv(os.path.join(DATA_DIR, \"KPoEM_poem_dataset_v3.tsv\"), sep='\\t')\n",
    "\n",
    "    line_df.rename(columns={'본문': 'text'}, inplace=True)\n",
    "    poem_df.rename(columns={'본문': 'text'}, inplace=True)\n",
    "\n",
    "    line_df = preprocess_by_paper_method(line_df.copy(), threshold=0.2)  # 임계값 분포에 따른 수정\n",
    "    poem_df = preprocess_by_paper_method(poem_df.copy(), threshold=0.2)  # 임계값 분포에 따른 수정\n",
    "\n",
    "    line_train_val, line_test = train_test_split(line_df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    line_train, line_val = train_test_split(line_train_val, test_size=1/9, random_state=RANDOM_SEED)\n",
    "    poem_train_val, poem_test = train_test_split(poem_df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "    poem_train, poem_val = train_test_split(poem_train_val, test_size=1/9, random_state=RANDOM_SEED)\n",
    "\n",
    "    kpoem_train_df = pd.concat([line_train, poem_train], ignore_index=True)\n",
    "    kpoem_val_df = pd.concat([line_val, poem_val], ignore_index=True)\n",
    "    kpoem_test_df = pd.concat([line_test, poem_test], ignore_index=True)\n",
    "\n",
    "    print(f\"KPoEM 데이터셋: Train {len(kpoem_train_df)}, Val {len(kpoem_val_df)}, Test {len(kpoem_test_df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: KPoEM 데이터 파일을 '{os.path.join(DATA_DIR, 'KPoEM_...tsv')}' 경로에서 찾을 수 없습니다.\")\n",
    "    kpoem_train_df, kpoem_val_df, kpoem_test_df = None, None, None\n",
    "\n",
    "\n",
    "# 2.3. KOTE 데이터 로드 및 분할 (수정)\n",
    "print(\"\\n>>> KOTE 데이터셋 준비 중 (로컬 tsv 파일 로드)...\")\n",
    "try:\n",
    "    kote_data_path = os.path.join(DATA_DIR)\n",
    "\n",
    "    # tsv 파일에 컬럼명이 없으므로 지정\n",
    "    kote_train_df = pd.read_csv(os.path.join(kote_data_path, 'train.tsv'), sep='\\t', header=None, names=['text', 'labels'])\n",
    "    kote_val_df = pd.read_csv(os.path.join(kote_data_path, 'val.tsv'), sep='\\t', header=None, names=['text', 'labels'])\n",
    "    kote_test_df = pd.read_csv(os.path.join(kote_data_path, 'test.tsv'), sep='\\t', header=None, names=['text', 'labels'])\n",
    "\n",
    "    # 각 데이터프레임에 새로 정의한 KOTE 전용 전처리 함수 적용\n",
    "    kote_train_df = preprocess_kote(kote_train_df.copy())  # 수정\n",
    "    kote_val_df = preprocess_kote(kote_val_df.copy())      # 수정\n",
    "    kote_test_df = preprocess_kote(kote_test_df.copy())    # 수정\n",
    "\n",
    "    print(f\"KOTE 데이터셋 로드 및 전처리 완료: Train {len(kote_train_df)}, Val {len(kote_val_df)}, Test {len(kote_test_df)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"경고: KOTE tsv 파일을 '{os.path.join(DATA_DIR)}' 디렉토리에서 찾을 수 없습니다.\")\n",
    "    print(\"모델 B 학습을 건너뜁니다.\")\n",
    "    kote_train_df, kote_val_df, kote_test_df = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNOv8Q53kRrB"
   },
   "source": [
    "## 3. Core components definition (Dataset, DataModule, LightningModule)\n",
    "- Define Core Components (Model Pipeline)\n",
    "  - Loads the tokenizer for KcELECTRA.\n",
    "  - Defines `PoetryDataset` (PyTorch Dataset) and `PoetryDataModule` (Lightning DataModule).\n",
    "  - Defines `BaseTagger`, a PyTorch Lightning module using KcELECTRA and a linear classifier with sigmoid for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Fq_JrBNWS4yY"
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 3. 코어 컴포넌트 정의 (Dataset, DataModule, LightningModule)\n",
    "# ===================================================================\n",
    "\n",
    "# 3.1. 토크나이저 로드\n",
    "MODEL_NAME = \"beomi/KcELECTRA-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "# 3.2. Pytorch Dataset 정의\n",
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df['label_vector'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = torch.FloatTensor(self.labels[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "\n",
    "# 3.3. Pytorch Lightning DataModule 정의\n",
    "class PoetryDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, val_df, test_df, tokenizer, batch_size=16, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        # Jupyter Notebook 환경에서는 num_workers를 0 또는 2로 설정하는 것이 안정적\n",
    "        self.num_workers = 8 if torch.cuda.is_available() else 0  # 서버가 16코어라서 절반인 8로 설정\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = PoetryDataset(self.train_df, self.tokenizer, self.max_length)\n",
    "            self.val_dataset = PoetryDataset(self.val_df, self.tokenizer, self.max_length)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = PoetryDataset(self.test_df, self.tokenizer, self.max_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "# 3.4. Pytorch Lightning 모델(BaseTagger) 정의\n",
    "class BaseTagger(pl.LightningModule):\n",
    "    def __init__(self, model_name=MODEL_NAME, lr=2e-5, weight_decay=0.01,\n",
    "                 n_training_steps=None, n_warmup_steps=None, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.electra = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=self.hparams.dropout_rate),\n",
    "            nn.Linear(self.electra.config.hidden_size, len(LABELS))\n",
    "        )\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.electra(input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(output.last_hidden_state[:, 0, :])\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(probs, labels)\n",
    "            return loss, probs\n",
    "        return None, probs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self(**batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _ = self(**batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.n_warmup_steps,\n",
    "            num_training_steps=self.hparams.n_training_steps\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_nuqxz9kUTh"
   },
   "source": [
    "## Finetuning KcELECTRA <- KPoEM\n",
    "- Experiment A: Fine-Tuning KcELECTRA on KPoEM\n",
    "  - Uses Optuna to search for optimal hyperparameters (batch size, LR, dropout, etc.) using the KPoEM train/val split.\n",
    "  - Fine-tunes the model using the best hyperparameters and saves the best checkpoint based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4002a4fcae1a4af096dbbca7edbcb8dc",
      "f726d6ac50644466afb34d79956b10ac",
      "103534d6d1934c749c6debbf471e1339",
      "5c1bdb01a1bf4e998cbee4db8998e925",
      "fd128dc1e2db4b33b562c3bd052b9ff1",
      "016bf5c413cc4ecb94c6b4bfa7cf40d4",
      "afc37e1449d14bedbee3a97374a355ea",
      "3306b77689764591b2a4e9d832d3c365",
      "d9d844d432a34f2084f6609addc3119a",
      "34fd1c80186242cba52330131b48c1b1",
      "c36b87c162454518b8ec91ed1b8560be",
      "2811ea3f6c7241c18ce44a7f18783457"
     ]
    },
    "id": "evCmuSITS4yl",
    "outputId": "8127e6ea-8cfd-4ce6-a336-811e5cc08df9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 12:38:08,374] A new study created in memory with name: no-name-af82eea9-bcdf-4bfb-9035-0cd93d8fcc62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "실험 A: KcELECTRA + KPoEM 시작\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69977e3751c4980af9ca4c83546bef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 12:40:56,768] Trial 0 finished with value: 0.4678395986557007 and parameters: {'batch_size': 8, 'lr': 2.847379847566484e-06, 'weight_decay': 0.0014415826469109975, 'dropout_rate': 0.43468611081368713}. Best is trial 0 with value: 0.4678395986557007.\n",
      "[I 2025-07-16 12:43:17,018] Trial 1 finished with value: 0.41470828652381897 and parameters: {'batch_size': 16, 'lr': 1.7252857657193505e-05, 'weight_decay': 0.043068021782814714, 'dropout_rate': 0.2989252492695914}. Best is trial 1 with value: 0.41470828652381897.\n",
      "[I 2025-07-16 12:45:38,921] Trial 2 finished with value: 0.4627493917942047 and parameters: {'batch_size': 16, 'lr': 4.472565276029557e-06, 'weight_decay': 0.07802007461654094, 'dropout_rate': 0.2035362673151888}. Best is trial 1 with value: 0.41470828652381897.\n",
      "[I 2025-07-16 12:48:29,507] Trial 3 finished with value: 0.46189162135124207 and parameters: {'batch_size': 8, 'lr': 3.24837637815585e-06, 'weight_decay': 4.828932732084535e-05, 'dropout_rate': 0.23505436797111307}. Best is trial 1 with value: 0.41470828652381897.\n",
      "[I 2025-07-16 12:50:55,885] Trial 4 finished with value: 0.42688676714897156 and parameters: {'batch_size': 16, 'lr': 1.098575098238942e-05, 'weight_decay': 0.04592177928622076, 'dropout_rate': 0.1373245173550316}. Best is trial 1 with value: 0.41470828652381897.\n",
      "[I 2025-07-16 12:53:53,165] Trial 5 finished with value: 0.47935202717781067 and parameters: {'batch_size': 8, 'lr': 1.9354231105281355e-06, 'weight_decay': 1.0739090201747213e-05, 'dropout_rate': 0.18641207416717825}. Best is trial 1 with value: 0.41470828652381897.\n",
      "[I 2025-07-16 12:56:45,848] Trial 6 finished with value: 0.40075334906578064 and parameters: {'batch_size': 8, 'lr': 1.7201759862605634e-05, 'weight_decay': 2.7335692030682323e-05, 'dropout_rate': 0.3495126813801242}. Best is trial 6 with value: 0.40075334906578064.\n",
      "[I 2025-07-16 12:59:48,929] Trial 7 finished with value: 0.46547630429267883 and parameters: {'batch_size': 8, 'lr': 3.0727461914649455e-06, 'weight_decay': 0.00014889356548028164, 'dropout_rate': 0.3571207193160334}. Best is trial 6 with value: 0.40075334906578064.\n",
      "[I 2025-07-16 13:02:25,353] Trial 8 finished with value: 0.4345893859863281 and parameters: {'batch_size': 16, 'lr': 9.687098040792931e-06, 'weight_decay': 0.015340628499524025, 'dropout_rate': 0.2882228317569199}. Best is trial 6 with value: 0.40075334906578064.\n",
      "[I 2025-07-16 13:05:02,783] Trial 9 finished with value: 0.4818209707736969 and parameters: {'batch_size': 16, 'lr': 3.0203140604532417e-06, 'weight_decay': 0.0007184342510733637, 'dropout_rate': 0.2825553951006905}. Best is trial 6 with value: 0.40075334906578064.\n",
      "[I 2025-07-16 13:08:14,290] Trial 10 finished with value: 0.38767802715301514 and parameters: {'batch_size': 8, 'lr': 4.4097126004891655e-05, 'weight_decay': 2.1105536920369742e-05, 'dropout_rate': 0.4463760277109804}. Best is trial 10 with value: 0.38767802715301514.\n",
      "[I 2025-07-16 13:11:28,861] Trial 11 finished with value: 0.3852192759513855 and parameters: {'batch_size': 8, 'lr': 4.7841593120174555e-05, 'weight_decay': 1.1072885297419562e-05, 'dropout_rate': 0.4992724822603081}. Best is trial 11 with value: 0.3852192759513855.\n",
      "[I 2025-07-16 13:14:33,589] Trial 12 finished with value: 0.38854584097862244 and parameters: {'batch_size': 8, 'lr': 4.9394902680718823e-05, 'weight_decay': 0.00016254678361526923, 'dropout_rate': 0.4988952823672462}. Best is trial 11 with value: 0.3852192759513855.\n",
      "[I 2025-07-16 13:17:32,160] Trial 13 finished with value: 0.38719815015792847 and parameters: {'batch_size': 8, 'lr': 4.554699758483989e-05, 'weight_decay': 1.1485808602486253e-05, 'dropout_rate': 0.49318921442731223}. Best is trial 11 with value: 0.3852192759513855.\n",
      "[I 2025-07-16 13:20:48,229] Trial 14 finished with value: 0.395809143781662 and parameters: {'batch_size': 8, 'lr': 2.7534954753162693e-05, 'weight_decay': 0.00011218007216561092, 'dropout_rate': 0.49106384105793516}. Best is trial 11 with value: 0.3852192759513855.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 A (KPoEM) 최적 하이퍼파라미터: {'batch_size': 8, 'lr': 4.7841593120174555e-05, 'weight_decay': 1.1072885297419562e-05, 'dropout_rate': 0.4992724822603081}\n",
      "\n",
      ">>> 모델 A 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/work/KPoEM/code/model/model_A exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d4d4a35ba3429da7f079de9d67b4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61603527c9454873a2b78f9879b8236a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a39ef7429147458c471e06d1f0d57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce034b59e6df4ab0b7bcad29aebf0dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8898381f3a934906b58173c1e84fa4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd44e36694994e878c0c1e5704b260ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80b0d33c4e5480db47417f8b8ca6107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fc6437654440f9b01a3be5f440bbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33455d4a0dab4e85bfe18135e08f68eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f93eb9c40514073995f520f15aeefa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6dae103a6c4be3a3d241321ae7e5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da57cca13514ae4a3cc86fa1697a556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 A 학습 완료 및 저장: /home/work/KPoEM/code/model/model_A/best_model_A_minmax_0.2.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 4. KcELECTRA + KPoEM\n",
    "# ===================================================================\n",
    "print(\"=\"*50)\n",
    "print(\"실험 A: KcELECTRA + KPoEM 시작\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 4.1. KPoEM 최적 하이퍼파라미터 탐색 (Optuna)\n",
    "def objective_kpoem(trial):\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 5e-5, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "\n",
    "    data_module = PoetryDataModule(kpoem_train_df, kpoem_val_df, kpoem_test_df, tokenizer, batch_size=batch_size)\n",
    "    steps_per_epoch = len(kpoem_train_df) // batch_size\n",
    "    n_training_steps = steps_per_epoch * N_EPOCHS_OPTUNA\n",
    "    n_warmup_steps = int(n_training_steps * 0.1)\n",
    "\n",
    "    model = BaseTagger(\n",
    "        lr=lr, weight_decay=weight_decay, dropout_rate=dropout_rate,\n",
    "        n_training_steps=n_training_steps, n_warmup_steps=n_warmup_steps\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=N_EPOCHS_OPTUNA, accelerator='gpu', devices=1,\n",
    "        enable_checkpointing=False, logger=False, enable_progress_bar=False\n",
    "    )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    return trainer.callback_metrics['val_loss'].item()\n",
    "\n",
    "study_kpoem = optuna.create_study(direction='minimize')\n",
    "study_kpoem.optimize(objective_kpoem, n_trials=15) # n_trials는 필요에 따라 조절\n",
    "best_hparams_A = study_kpoem.best_params\n",
    "print(f\"모델 A (KPoEM) 최적 하이퍼파라미터: {best_hparams_A}\")\n",
    "\n",
    "\n",
    "# 4.2. 모델 A 학습 및 저장\n",
    "batch_size_A = best_hparams_A['batch_size']\n",
    "dm_A = PoetryDataModule(kpoem_train_df, kpoem_val_df, kpoem_test_df, tokenizer, batch_size=batch_size_A)\n",
    "steps_per_epoch_A = len(kpoem_train_df) // batch_size_A\n",
    "n_training_steps_A = steps_per_epoch_A * N_EPOCHS_TRAIN\n",
    "n_warmup_steps_A = int(n_training_steps_A * 0.1)\n",
    "\n",
    "model_A = BaseTagger(\n",
    "    lr=best_hparams_A['lr'], weight_decay=best_hparams_A['weight_decay'], dropout_rate=best_hparams_A['dropout_rate'],\n",
    "    n_training_steps=n_training_steps_A, n_warmup_steps=n_warmup_steps_A\n",
    ")\n",
    "\n",
    "checkpoint_callback_A = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=os.path.join(MODEL_SAVE_DIR, \"model_A\"), filename='best_model_A_minmax_0.2',\n",
    "    save_top_k=1, verbose=False, monitor='val_loss', mode='min'\n",
    ")\n",
    "trainer_A = pl.Trainer(\n",
    "    max_epochs=N_EPOCHS_TRAIN, accelerator='gpu', devices=1,\n",
    "    callbacks=[checkpoint_callback_A], logger=False\n",
    ")\n",
    "\n",
    "print(\"\\n>>> 모델 A 학습 시작...\")\n",
    "trainer_A.fit(model_A, datamodule=dm_A)\n",
    "best_model_A_path = checkpoint_callback_A.best_model_path\n",
    "print(f\"모델 A 학습 완료 및 저장: {best_model_A_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HoGp0Hckpao"
   },
   "source": [
    "## 5. Finetuning KcELCTRA <- KOTE <- KPoEM\n",
    "- Experiment B: Sequential Fine-Tuning (KOTE → KPoEM)\n",
    "  - Stage 1: Fine-tunes on KOTE dataset using Optuna hyperparameter search.\n",
    "    - Saves best model and optionally resumes from `last.ckpt` if it exists.\n",
    "  - Stage 2: Loads the fine-tuned KOTE model and further fine-tunes it on KPoEM using new hyperparameters via Optuna.\n",
    "    - Saves the best checkpoint after fine-tuning on KPoEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "402545bc52544a44be813e9cc55da99f",
      "e79870e5455e4d6db7851fccba880fdb",
      "c34973bc773d448395cda89205edd895",
      "98c9e3bc7cce4d41bd7beda6b587df5f",
      "4acb17fd33ac46498f300a8372a6229c",
      "dba3f17117d54c5884a63f1a9cbe2b03",
      "396d0a1b47304a5b8e5c0b042b65aef9",
      "35fbe5040e7446819a0db38e18ec088c",
      "51867b719d84426e945f24ba62dd3ef9",
      "911576bb39fe4e8fbcfb03408f95161b",
      "4f3853d20f694a869ef4cfb231e71a63",
      "86dd097062cf4911ac2df5a5d49596a4",
      "d7d22039e2f54a069bf8f94875dba53b",
      "18462aebef7e46658bed30fab5a52778",
      "e60bc088074b423bb3cc179a3e677660",
      "83c83dd4303545cfab0aa58bf23fe4aa",
      "25984cddabe64a1c8b73cbb46482b186",
      "cfecbaacc59a449e9204bae90ce7293b",
      "8927d7852c74474691ef0f7d622c3201",
      "18331edca5d9482b87b8e72e366e14da",
      "55ed93e1c95b4b12920adee10dc1932e",
      "88d50656a54d4cafb4919066395d62c5",
      "854601e073c8481d93a6f69f3ec20c81",
      "a57b0be41b5d44c0ba249be1d7a6a2b5"
     ]
    },
    "id": "DKLDtkRTS4yl",
    "outputId": "508663b0-fcbd-46bd-a9cc-ab60941c47b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:29:09,099] A new study created in memory with name: no-name-8fefb228-40d2-4268-8a3e-8e0e5d158574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "실험 B: KcELECTRA -> KOTE -> KPoEM 시작\n",
      "==================================================\n",
      "\n",
      "5.1. 1차 파인튜닝 (on KOTE)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 14:47:11,894] Trial 0 finished with value: 0.2828691303730011 and parameters: {'batch_size': 8, 'lr': 4.8604114137205645e-05, 'weight_decay': 2.7142729477778773e-05, 'dropout_rate': 0.4465368526171606}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 15:06:32,290] Trial 1 finished with value: 0.29127418994903564 and parameters: {'batch_size': 8, 'lr': 7.746238499928332e-06, 'weight_decay': 0.0002083926840415501, 'dropout_rate': 0.2179687744124289}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 15:21:36,779] Trial 2 finished with value: 0.346828430891037 and parameters: {'batch_size': 16, 'lr': 2.3661690141901758e-06, 'weight_decay': 0.0005285955822268571, 'dropout_rate': 0.34038130235970554}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 15:36:41,403] Trial 3 finished with value: 0.33044981956481934 and parameters: {'batch_size': 16, 'lr': 3.5605151969134866e-06, 'weight_decay': 0.0005197611585358328, 'dropout_rate': 0.3081602765153682}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 15:54:48,066] Trial 4 finished with value: 0.3369283080101013 and parameters: {'batch_size': 8, 'lr': 1.8859909727202007e-06, 'weight_decay': 0.023721542529379396, 'dropout_rate': 0.4129898604633736}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 16:09:55,386] Trial 5 finished with value: 0.38045933842658997 and parameters: {'batch_size': 16, 'lr': 1.2881413609278745e-06, 'weight_decay': 0.04189328529512643, 'dropout_rate': 0.4159847617768009}. Best is trial 0 with value: 0.2828691303730011.\n",
      "[I 2025-07-16 16:25:05,040] Trial 6 finished with value: 0.2811356484889984 and parameters: {'batch_size': 16, 'lr': 4.6049943042870796e-05, 'weight_decay': 1.6478050426132122e-05, 'dropout_rate': 0.13151555290957978}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 16:43:52,556] Trial 7 finished with value: 0.32467934489250183 and parameters: {'batch_size': 8, 'lr': 2.466721183610993e-06, 'weight_decay': 0.041576233172901975, 'dropout_rate': 0.24981732690789402}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 17:02:23,215] Trial 8 finished with value: 0.3141193091869354 and parameters: {'batch_size': 8, 'lr': 3.358221175584841e-06, 'weight_decay': 6.063211227854829e-05, 'dropout_rate': 0.21882710589294685}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 17:20:46,131] Trial 9 finished with value: 0.2949860394001007 and parameters: {'batch_size': 8, 'lr': 7.303792984943828e-06, 'weight_decay': 0.00385771877828966, 'dropout_rate': 0.4935628864189}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 17:36:00,913] Trial 10 finished with value: 0.2812236547470093 and parameters: {'batch_size': 16, 'lr': 4.378755186091723e-05, 'weight_decay': 1.0926045586950756e-05, 'dropout_rate': 0.11086507113308233}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 17:51:12,346] Trial 11 finished with value: 0.2813015282154083 and parameters: {'batch_size': 16, 'lr': 4.77486835375012e-05, 'weight_decay': 1.1680184718804683e-05, 'dropout_rate': 0.12605786071737962}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 18:06:23,851] Trial 12 finished with value: 0.28243139386177063 and parameters: {'batch_size': 16, 'lr': 1.9672577425238996e-05, 'weight_decay': 0.0001165416930152356, 'dropout_rate': 0.10582046401630672}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 18:21:37,946] Trial 13 finished with value: 0.2835729122161865 and parameters: {'batch_size': 16, 'lr': 2.1539716468896627e-05, 'weight_decay': 1.294063194198263e-05, 'dropout_rate': 0.16135357172149908}. Best is trial 6 with value: 0.2811356484889984.\n",
      "[I 2025-07-16 18:36:52,794] Trial 14 finished with value: 0.2832520306110382 and parameters: {'batch_size': 16, 'lr': 2.2535239223983925e-05, 'weight_decay': 4.682883856246655e-05, 'dropout_rate': 0.163599147701868}. Best is trial 6 with value: 0.2811356484889984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 1차(KOTE) 모델 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/work/KPoEM/code/model/kote_tuned exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b2928111894637a04979043b0c6435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b292f9d95321491eab0946523affcb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948e836e1ceb404eaaf8161d4a953b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93a5ea1f7a4002b94c35f0f4e4d927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f89b1770e4f4674b6f1e669ff2f1f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862a967d9ae94e81bf6ec705875501d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6437a4690ef4118b352271b3597fede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e7c26f5e2c4d839db63eb2893b15cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba12b454de04a12a9fb818cf14a7147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7ef6cb37bb4dee86007013166e1ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f25b2243b4eb99c7fd0edce9b75a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317ebc58889440cba3a890fb21c32cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1차(KOTE) 모델 학습 완료 및 저장: /home/work/KPoEM/code/model/kote_tuned/kote_finetuned-epochepoch=01-val_lossval_loss=0.29_minmax_0.2.ckpt\n",
      "\n",
      "5.2. 2차 파인튜닝 (on KPoEM)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 19:29:27,444] Using an existing study with name 'kote-kpoem-hyper-tuning-minmax-0.2' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 B Optuna 탐색이 이미 완료되었습니다.\n",
      "모델 B (KOTE->KPoEM) 최적 하이퍼파라미터: {'batch_size': 16, 'lr': 1.8726765536618316e-05, 'weight_decay': 7.304905716726998e-05}\n",
      "\n",
      ">>> 모델 B 최종 학습 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/work/KPoEM/code/model/model_B exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297270c990c0468fbfac9edb7532c762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858f9b9666bc4ae68eaa7bf2e1969bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1657fdd68ac846ad9ae57345f144f497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb632e211204f53a5e3f3745b5c46e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fd37a7ab1f4cff98a2109488f182dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2b14105df440e8bc08bf948f87d4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53a38df22f04d30bd69fbff430e7472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cc460b541a4524aab8fdd902155148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200983e455fc490abccc9663eb183123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6314df0dc634480fa239a5edca1eb62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c2a809140145adb87f8315fabd9895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c9b918bb864f10ab6f70ae6022521e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 B 학습 완료 및 저장: /home/work/KPoEM/code/model/model_B/best_model_B_minmax_0.2.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 5. KcELECTRA -> KOTE -> KPoEM\n",
    "# ===================================================================\n",
    "if kote_train_df is not None and 'kpoem_train_df' in locals() and kpoem_train_df is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"실험 B: KcELECTRA -> KOTE -> KPoEM 시작\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "    # 5.1. 1차 파인튜닝 (KOTE 데이터)\n",
    "    print(\"\\n5.1. 1차 파인튜닝 (on KOTE)\")\n",
    "    def objective_kote(trial):\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "        lr = trial.suggest_float(\"lr\", 1e-6, 5e-5, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "\n",
    "        data_module = PoetryDataModule(kote_train_df, kote_val_df, kote_test_df, tokenizer, batch_size=batch_size)\n",
    "        steps_per_epoch = len(kote_train_df) // batch_size\n",
    "        n_training_steps = steps_per_epoch * N_EPOCHS_OPTUNA\n",
    "        n_warmup_steps = int(n_training_steps * 0.1)\n",
    "\n",
    "        model = BaseTagger(\n",
    "            lr=lr, weight_decay=weight_decay, dropout_rate=dropout_rate,\n",
    "            n_training_steps=n_training_steps, n_warmup_steps=n_warmup_steps\n",
    "        )\n",
    "        trainer = pl.Trainer(max_epochs=N_EPOCHS_OPTUNA, accelerator='gpu', devices=1, enable_checkpointing=False, logger=False, enable_progress_bar=False)\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "        return trainer.callback_metrics['val_loss'].item()\n",
    "\n",
    "    # optuna로 처음부터 찾는 경우\n",
    "    study_kote = optuna.create_study(direction='minimize')\n",
    "    study_kote.optimize(objective_kote, n_trials=15)\n",
    "    best_hparams_kote = study_kote.best_params\n",
    "\n",
    "\n",
    "    # 1차 파인튜닝 모델 학습\n",
    "    batch_size_kote = best_hparams_kote['batch_size']\n",
    "    dm_kote = PoetryDataModule(kote_train_df, kote_val_df, kote_test_df, tokenizer, batch_size=batch_size_kote)\n",
    "    steps_per_epoch_kote = len(kote_train_df) // batch_size_kote\n",
    "    n_training_steps_kote = steps_per_epoch_kote * N_EPOCHS_TRAIN\n",
    "    n_warmup_steps_kote = int(n_training_steps_kote * 0.1)\n",
    "\n",
    "    model_kote_tuned = BaseTagger(\n",
    "        lr=best_hparams_kote['lr'],\n",
    "        weight_decay=best_hparams_kote['weight_decay'],\n",
    "        dropout_rate=best_hparams_kote['dropout_rate'],\n",
    "        n_training_steps=n_training_steps_kote,\n",
    "        n_warmup_steps=n_warmup_steps_kote\n",
    "    )\n",
    "\n",
    "    kote_ckpt_dir = os.path.join(MODEL_SAVE_DIR, \"kote_tuned\")\n",
    "    checkpoint_callback_kote = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=kote_ckpt_dir,\n",
    "        filename='kote_finetuned-epoch{epoch:02d}-val_loss{val_loss:.2f}_minmax_0.2',  # val_loss도 파일명에 포함\n",
    "        save_top_k=1,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_last=True\n",
    "    )\n",
    "    trainer_kote = pl.Trainer(max_epochs=N_EPOCHS_TRAIN, accelerator='gpu', devices=1, callbacks=[checkpoint_callback_kote], logger=False)\n",
    "\n",
    "    last_ckpt_path = os.path.join(kote_ckpt_dir, \"last_minmax.ckpt\")\n",
    "    resume_path = last_ckpt_path if os.path.exists(last_ckpt_path) else None\n",
    "\n",
    "    if resume_path:\n",
    "        print(f\"기존 KOTE 학습 체크포인트({resume_path})를 발견하여 이어서 학습합니다.\")\n",
    "    else:\n",
    "        print(\"\\n>>> 1차(KOTE) 모델 학습 시작...\")\n",
    "\n",
    "    trainer_kote.fit(model_kote_tuned, datamodule=dm_kote, ckpt_path=resume_path)\n",
    "    kote_finetuned_ckpt_path = checkpoint_callback_kote.best_model_path\n",
    "    print(f\"1차(KOTE) 모델 학습 완료 및 저장: {kote_finetuned_ckpt_path}\")\n",
    "\n",
    "\n",
    "    # 5.2. 2차 파인튜닝 (KPoEM 데이터)\n",
    "    print(\"\\n5.2. 2차 파인튜닝 (on KPoEM)\")\n",
    "\n",
    "    # objective 함수가 batch_size까지 새로 탐색하도록 수정\n",
    "    ## KcELECTRA + KOTE에 맞는 새로운 hparams 탐색 필요!\n",
    "    def objective_kote_kpoem(trial):\n",
    "        # batch_size도 새로 탐색\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16])\n",
    "        lr = trial.suggest_float(\"lr\", 1e-7, 2e-5, log=True)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "        # 이번 trial의 batch_size로 데이터 모듈과 학습 스텝 새로 계산\n",
    "        data_module = PoetryDataModule(kpoem_train_df, kpoem_val_df, kpoem_test_df, tokenizer, batch_size=batch_size)\n",
    "        steps_per_epoch = len(kpoem_train_df) // batch_size\n",
    "        n_training_steps = steps_per_epoch * N_EPOCHS_OPTUNA\n",
    "        n_warmup_steps = int(n_training_steps * 0.1)\n",
    "\n",
    "        # 1차 학습된 모델을 불러와서 새 하이퍼파라미터로 학습\n",
    "        model = BaseTagger.load_from_checkpoint(\n",
    "            kote_finetuned_ckpt_path,\n",
    "            lr=lr, weight_decay=weight_decay,\n",
    "            n_training_steps=n_training_steps, # 새로 계산된 스텝 사용\n",
    "            n_warmup_steps=n_warmup_steps      # 새로 계산된 스텝 사용\n",
    "        )\n",
    "        trainer = pl.Trainer(max_epochs=N_EPOCHS_OPTUNA, accelerator='gpu', devices=1, enable_checkpointing=False, logger=False, enable_progress_bar=False)\n",
    "\n",
    "        # 새로 만든 data_module을 사용\n",
    "        trainer.fit(model, datamodule=data_module)\n",
    "        return trainer.callback_metrics['val_loss'].item()\n",
    "\n",
    "    # Optuna 탐색 이어하기 기능 추가\n",
    "    study_db_path_b = os.path.join(MODEL_SAVE_DIR, \"study_model_B_minmax_0.2.db\")\n",
    "    study_name_b = \"kote-kpoem-hyper-tuning-minmax-0.2\"\n",
    "    n_trials_b = 15\n",
    "\n",
    "    study_kote_kpoem = optuna.create_study(\n",
    "        study_name=study_name_b,\n",
    "        storage=f\"sqlite:///{study_db_path_b}\",\n",
    "        direction='minimize',\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    if len(study_kote_kpoem.trials) < n_trials_b:\n",
    "        print(f\"모델 B Optuna 탐색을 이어합니다. (현재 {len(study_kote_kpoem.trials)} / 목표 {n_trials_b})\")\n",
    "        study_kote_kpoem.optimize(objective_kote_kpoem, n_trials=(n_trials_b - len(study_kote_kpoem.trials)))\n",
    "    else:\n",
    "        print(\"모델 B Optuna 탐색이 이미 완료되었습니다.\")\n",
    "\n",
    "    best_hparams_B = study_kote_kpoem.best_params\n",
    "    print(f\"모델 B (KOTE->KPoEM) 최적 하이퍼파라미터: {best_hparams_B}\")\n",
    "\n",
    "\n",
    "    # 최종 모델 B 학습 및 저장\n",
    "    batch_size_B = best_hparams_B['batch_size']\n",
    "    dm_B_final = PoetryDataModule(kpoem_train_df, kpoem_val_df, kpoem_test_df, tokenizer, batch_size=batch_size_B)\n",
    "    steps_per_epoch_B = len(kpoem_train_df) // batch_size_B\n",
    "    n_training_steps_B = steps_per_epoch_B * N_EPOCHS_TRAIN\n",
    "    n_warmup_steps_B = int(n_training_steps_B * 0.1)\n",
    "\n",
    "    model_B_final = BaseTagger.load_from_checkpoint(\n",
    "        kote_finetuned_ckpt_path,\n",
    "        lr=best_hparams_B['lr'], weight_decay=best_hparams_B['weight_decay'],\n",
    "        n_training_steps=n_training_steps_B,  # 새로 계산된 스텝 B 사용\n",
    "        n_warmup_steps=n_warmup_steps_B       # 새로 계산된 스텝 B 사용\n",
    "    )\n",
    "    # 최종 학습도 이어하기 가능하도록 수정\n",
    "    model_b_ckpt_dir = os.path.join(MODEL_SAVE_DIR, \"model_B\")\n",
    "    checkpoint_callback_B = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=model_b_ckpt_dir,\n",
    "        filename='best_model_B_minmax_0.2',\n",
    "        save_top_k=1,\n",
    "        verbose=False,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_last=True\n",
    "    )\n",
    "    trainer_B = pl.Trainer(\n",
    "        max_epochs=N_EPOCHS_TRAIN, accelerator='gpu', devices=1,\n",
    "        callbacks=[checkpoint_callback_B], logger=False\n",
    "    )\n",
    "\n",
    "    last_ckpt_path_B = os.path.join(model_b_ckpt_dir, \"last_minmax_0.2.ckpt\")\n",
    "    resume_path_B = last_ckpt_path_B if os.path.exists(last_ckpt_path_B) else None\n",
    "\n",
    "    if resume_path_B:\n",
    "        print(f\"기존 모델 B 학습 체크포인트({resume_path_B})를 발견하여 이어서 학습합니다.\")\n",
    "    else:\n",
    "        print(\"\\n>>> 모델 B 최종 학습 시작...\")\n",
    "\n",
    "    # dm_A 대신 새로 만든 dm_B_final 사용 및 ckpt_path 추가\n",
    "    trainer_B.fit(model_B_final, datamodule=dm_B_final, ckpt_path=resume_path_B)\n",
    "    best_model_B_path = checkpoint_callback_B.best_model_path\n",
    "    print(f\"모델 B 학습 완료 및 저장: {best_model_B_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e69U7_lXlJz4"
   },
   "source": [
    "## 6. Final performance evaluation\n",
    "- Final Evaluation\n",
    "  - Loads all three best models:\n",
    "    - A: KcELECTRA + KPoEM\n",
    "    - B: KcELECTRA + KOTE → KPoEM\n",
    "    - C: KcELECTRA + KOTE\n",
    "  - Evaluates all models on the same KPoEM test set.\n",
    "  - Computes and reports metrics: micro/macro precision, recall, F1, accuracy, and MCC.\n",
    "  - Saves the results in a timestamped `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "88ab38d2bd3744c193e590c8a6e067ec",
      "50a281b9db5b42f981237c4445623692",
      "5323c9bab7e64bd69e850815393f75f1"
     ]
    },
    "id": "ong7nKX9S4ym",
    "outputId": "c29f7557-40da-4439-880d-c5d796ea32e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "최종 성능 비교\n",
      "==================================================\n",
      "\n",
      ">>> 모델 A_minmax_0.2 평가 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32583c88d33749abb01ea53e3f3a4e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 모델 C_minmax_0.2 (KcELECTRA + KOTE) 평가 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffab5ae65134bd6a1840b3c6bd3a66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 모델 B_minmax_0.2 (KOTE -> KPoEM) 평가 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70780478b1f400f8c7edc4772c7ce07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 비교 결과\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_micro</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_micro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A (KcELECTRA + KPoEM)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.525362</td>\n",
       "      <td>0.432591</td>\n",
       "      <td>0.662394</td>\n",
       "      <td>0.499918</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.445955</td>\n",
       "      <td>0.452311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C (KcELECTRA + KOTE)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.769957</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.461387</td>\n",
       "      <td>0.381210</td>\n",
       "      <td>0.330282</td>\n",
       "      <td>0.427629</td>\n",
       "      <td>0.343058</td>\n",
       "      <td>0.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B (KOTE -&gt; KPoEM)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.792804</td>\n",
       "      <td>0.531072</td>\n",
       "      <td>0.471699</td>\n",
       "      <td>0.691068</td>\n",
       "      <td>0.541541</td>\n",
       "      <td>0.600597</td>\n",
       "      <td>0.486466</td>\n",
       "      <td>0.471266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Threshold  Accuracy  Precision_micro  \\\n",
       "0  A (KcELECTRA + KPoEM)        0.3  0.788991         0.525362   \n",
       "1   C (KcELECTRA + KOTE)        0.3  0.769957         0.486920   \n",
       "2      B (KOTE -> KPoEM)        0.3  0.792804         0.531072   \n",
       "\n",
       "   Precision_macro  Recall_micro  Recall_macro  F1_micro  F1_macro       MCC  \n",
       "0         0.432591      0.662394      0.499918  0.585973  0.445955  0.452311  \n",
       "1         0.461387      0.381210      0.330282  0.427629  0.343058  0.289700  \n",
       "2         0.471699      0.691068      0.541541  0.600597  0.486466  0.471266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결과 파일 저장 완료: ./model/final_minmax_0.2_comparison_250716_194211.tsv\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 6. 최종 성능 비교\n",
    "# ===================================================================\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from torchmetrics.functional.classification import multilabel_accuracy\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"최종 성능 비교\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 저장된 모델 경로를 직접 지정\n",
    "\n",
    "# 모델 A의 'best' 체크포인트 경로\n",
    "best_model_A_path = \"./model/model_A/best_model_A_minmax_0.2.ckpt\"\n",
    "\n",
    "# 모델 C (KOTE만 학습시킨 중간 모델)의 'best' 체크포인트 경로\n",
    "kote_finetuned_ckpt_path = \"./model/kote_tuned/kote_finetuned-epochepoch=02-val_lossval_loss=0.28_minmax_0.2.ckpt\"\n",
    "\n",
    "# 모델 B의 'best' 체크포인트 경로\n",
    "best_model_B_path = \"./model/model_B/best_model_B_minmax_0.2.ckpt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, test_dataset, device, threshold=THRESHOLD):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for item in tqdm(test_dataset, desc=\"Testing\"):\n",
    "        input_ids = item[\"input_ids\"].to(device).unsqueeze(0)\n",
    "        attention_mask = item[\"attention_mask\"].to(device).unsqueeze(0)\n",
    "        labels = item[\"labels\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            _, preds = model(input_ids, attention_mask)\n",
    "        predictions_list.append(preds.flatten().cpu())\n",
    "        labels_list.append(labels.cpu())\n",
    "\n",
    "    predictions_tensor = torch.stack(predictions_list)\n",
    "    labels_tensor = torch.stack(labels_list)\n",
    "    y_true = labels_tensor.numpy().astype(int)\n",
    "    predictions_np = predictions_tensor.numpy()\n",
    "    y_pred_bin = (predictions_np > threshold).astype(int)\n",
    "\n",
    "    # 성능 지표\n",
    "    accuracy = multilabel_accuracy(torch.from_numpy(predictions_np), torch.from_numpy(y_true), num_labels=len(LABELS), threshold=threshold, average=\"micro\").item()\n",
    "    f1_micro = f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred_bin, average='macro', zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true.flatten(), y_pred_bin.flatten())\n",
    "    precision_micro = precision_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    recall_micro = recall_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred_bin, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred_bin, average='macro', zero_division=0)\n",
    "\n",
    "    # 반환 딕셔너리에 새로운 지표 추가\n",
    "    return {\n",
    "        \"Threshold\": threshold,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision_micro\": precision_micro, \"Recall_micro\": recall_micro, \"F1_micro\": f1_micro,\n",
    "        \"Precision_macro\": precision_macro, \"Recall_macro\": recall_macro, \"F1_macro\": f1_macro,\n",
    "        \"MCC\": mcc\n",
    "    }\n",
    "\n",
    "# 평가용 데이터셋 준비\n",
    "if 'kpoem_test_df' in locals() and kpoem_test_df is not None:\n",
    "    test_dataset = PoetryDataset(kpoem_test_df, tokenizer, MAX_LENGTH)\n",
    "\n",
    "    # 모델 평가 로직 (기존과 동일)\n",
    "    print(\"\\n>>> 모델 A_minmax_0.2 평가 중...\")\n",
    "    model_A_eval = BaseTagger.load_from_checkpoint(best_model_A_path)\n",
    "    results_A = evaluate_model(model_A_eval, test_dataset, device)\n",
    "    df_A = pd.DataFrame([results_A])\n",
    "    df_A[\"Model\"] = \"A (KcELECTRA + KPoEM)\"\n",
    "    df_list = [df_A]\n",
    "\n",
    "    if 'best_model_B_path' in locals() and best_model_B_path:\n",
    "        print(\"\\n>>> 모델 C_minmax_0.2 (KcELECTRA + KOTE) 평가 중...\")\n",
    "        model_C_eval = BaseTagger.load_from_checkpoint(kote_finetuned_ckpt_path)\n",
    "        results_C = evaluate_model(model_C_eval, test_dataset, device)\n",
    "        df_C = pd.DataFrame([results_C])\n",
    "        df_C[\"Model\"] = \"C (KcELECTRA + KOTE)\"\n",
    "        df_list.append(df_C)\n",
    "\n",
    "        print(\"\\n>>> 모델 B_minmax_0.2 (KOTE -> KPoEM) 평가 중...\")\n",
    "        model_B_eval = BaseTagger.load_from_checkpoint(best_model_B_path)\n",
    "        results_B = evaluate_model(model_B_eval, test_dataset, device)\n",
    "        df_B = pd.DataFrame([results_B])\n",
    "        df_B[\"Model\"] = \"B (KOTE -> KPoEM)\"\n",
    "        df_list.append(df_B)\n",
    "\n",
    "    final_results_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # 최종 결과 출력 및 저장\n",
    "    print(\"\\n최종 비교 결과\")\n",
    "\n",
    "    # display 할 컬럼 목록\n",
    "    display_cols = [\n",
    "        \"Model\", \"Threshold\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision_micro\", \"Precision_macro\",\n",
    "        \"Recall_micro\", \"Recall_macro\",\n",
    "        \"F1_micro\", \"F1_macro\",\n",
    "        \"MCC\"\n",
    "    ]\n",
    "    display(final_results_df[display_cols])\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "    save_path = os.path.join(MODEL_SAVE_DIR, f\"final_minmax_0.2_comparison_{timestamp}.tsv\")\n",
    "    final_results_df.to_csv(save_path, sep='\\t', index=False)\n",
    "    print(f\"\\n결과 파일 저장 완료: {save_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"KPoEM 테스트 데이터셋이 준비되지 않아 최종 평가를 건너뜁니다.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
