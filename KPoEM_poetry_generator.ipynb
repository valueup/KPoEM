{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the KPoEM Dataset and Model: Poetry Generation\n",
    "\n",
    "- **KPpEM Emoiton Classification Medel** : AKS-DHLAB. (2025). KPoEM  [Computer software]. Hugging Face. https://doi.org/10.57967/hf/6301 \n",
    "- This code is uploaded in AKS-DHLAB. (2025). KPoEM [Computer software]. GitHub. https://github.com/AKS-DHLAB/KPoEM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic setup and library imports\n",
    "- Import Libraries and Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub langchain langchain-core langchain-community langchain-huggingface \n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, ElectraModel, AutoModelForCausalLM, pipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the KPoEM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기초 세팅\n",
    "REPO_ID = \"AKS-DHLAB/KPoEM\" # 허깅페이스에 업로드된 감정분류모델 id\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #GPU 사용\n",
    "THRESH_HOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPoEM_Classifier 클래스\n",
    "class KPoEM_Classifier(nn.Module):\n",
    "    def __init__(self, repo_id, device):\n",
    "        self.labels = [\n",
    "            '불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경',\n",
    "            '기대감', '우쭐댐/무시함', '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적',\n",
    "            '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망', '한심함', '역겨움/징그러움',\n",
    "            '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음',\n",
    "            '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움',\n",
    "            '재미없음', '불쌍함/연민', '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰'\n",
    "        ]\n",
    "        num_labels = len(self.labels)\n",
    "        #모델 & 토크나이저 로드\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(repo_id) \n",
    "        self.electra = AutoModel.from_pretrained(repo_id)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.electra.config.hidden_size, num_labels)\n",
    "        )\n",
    "\n",
    "        weights_path = hf_hub_download(repo_id=repo_id, filename=\"classifier_state.bin\") #가중치 불러오기\n",
    "        self.classifier.load_state_dict(torch.load(weights_path, map_location=self.device))\n",
    "        self.to(self.device)\n",
    "        self.eval()\n",
    "\n",
    "    # 텍스트를 입력받아 최종 logits 반환\n",
    "    def forward(self, text: str):\n",
    "        encoding = self.tokenizer(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=512,\n",
    "          padding=\"max_length\",\n",
    "          truncation=True,\n",
    "          return_tensors='pt',\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.electra(\n",
    "                input_ids=encoding[\"input_ids\"],\n",
    "                attention_mask=encoding[\"attention_mask\"],\n",
    "                token_type_ids=encoding[\"token_type_ids\"]\n",
    "            )\n",
    "\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    def analyze(self, text: str, threshold=0):\n",
    "        logits = self.forward(text)\n",
    "        probabilities = torch.sigmoid(logits.squeeze()) #확률로 변환 → threshold 이상이면 선택\n",
    "        predictions = (probabilities > threshold).int()\n",
    "\n",
    "        result_dict = {\n",
    "            self.labels[i]: float(round(probabilities[i].item(), 3))\n",
    "            for i, label_id in enumerate(predictions)\n",
    "            if label_id == 1\n",
    "        }\n",
    "\n",
    "        # 확률값 기준 내림차순 정렬된 dict로 반환\n",
    "        result_dict = dict(sorted(result_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 'cpu' 환경에서 'AKS-DHLAB/KPoEM' 모델을 로드하고 있습니다 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ae3f3b0d774236915ec85bf3dd6748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd2613c8bb4e0c80c0249801eee310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b793e554674c8293f403ea9d9454ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568cd5d9f6e74004842b4d3c89ef9f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/823 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545228e1cc0e4329be0580c85ff05664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/434M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea56930208490bb408364bc1f3f275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "classifier_state.bin:   0%|          | 0.00/137k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPoEM 모델을 성공적으로 로드하였습니다.\n"
     ]
    }
   ],
   "source": [
    "# KPoEM 모델 로드\n",
    "print(f\"... '{DEVICE}' 환경에서 '{REPO_ID}' 모델을 로드하고 있습니다 ...\")\n",
    "kpoem_model = KPoEM_Classifier(repo_id=REPO_ID, device=DEVICE)\n",
    "print(\"KPoEM 모델을 성공적으로 로드하였습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'기대감': 0.919,\n",
       " '기쁨': 0.809,\n",
       " '즐거움/신남': 0.635,\n",
       " '행복': 0.622,\n",
       " '비장함': 0.511,\n",
       " '환영/호의': 0.496,\n",
       " '아껴주는': 0.372,\n",
       " '편안/쾌적': 0.32,\n",
       " '감동/감탄': 0.304}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 테스트\n",
    "test = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\"\n",
    "result = kpoem_model.analyze(test, threshold=THRESH_HOLD)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downloading and Loading the LLM for Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc2896e05584e5e9ba492369a43a370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243ab9bfc5df437ca724e55e13162aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9313af0cba458c98b6c95e75182cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ab9b6140b14abf9edc68a6cdfa8049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료. GPU/CPU 자동 오프로딩 활성화\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1847/3750988198.py:31: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n",
      "/tmp/ipykernel_1847/3750988198.py:40: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"K-intelligence/Midm-2.0-Base-Instruct\"\n",
    "CACHE_DIR = \"/home/work/KPoEM/code/AICreation/model\"\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "#모델 로드 - device_map=\"auto\" 유지 (자동 분산 로드)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",           # GPU + CPU 메모리 자동 분산\n",
    "    low_cpu_mem_usage=True,      # 로딩 시 CPU 메모리 절약\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(\"모델 로드 완료. GPU/CPU 자동 오프로딩 활성화\")\n",
    "\n",
    "# HuggingFace pipeline 생성 (device 설정하지 않아도 자동)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=512,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "# LangChain LLM 래퍼로 감싸기\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 간단한 프롬프트 템플릿\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"다음 주제로 감성적인 시를 써주세요:\\n주제: {topic}\\n\\n### 시:\\n\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt-Based Poetry Generation 1\n",
    "Using Input Text and Emotion Classification Results (Without a Vector Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감정 분류 모델만 적용하여 LLM으로 시 생성(Vector DB 미적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poetry_section(template):\n",
    "    # Split the template by \"### 시:\" and extract the part after it\n",
    "    if \"### 시:\" in template:\n",
    "        poetry_section = template.split(\"### 시:\")[1].strip()\n",
    "        # Split by lines and return as a list\n",
    "        poetry_lines = poetry_section.splitlines()\n",
    "        return poetry_lines\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ 전체 흐름 함수\n",
    "def emotion_to_poetry(sample_text): #감정 분류에 사용할 사용자 텍스트 인풋.\n",
    "    emotion_scores = kpoem_model.analyze(sample_text, threshold=0.3)\n",
    "    \n",
    "    template = \"\"\"\n",
    "    ### 시스템:\n",
    "    당신은 창의적이고 감성적인 근현대 시인입니다.\n",
    "    아래에 제시된 원문 텍스트와 감정 목록을 참고하여 시를 지으세요.\n",
    "    원문 텍스트는 시의 소재나 분위기를 떠올리는 데 활용하고,\n",
    "    감정 목록에 언급된 감정들을 시의 핵심 정서로 반영하세요.\n",
    "    \n",
    "    영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요.\n",
    "    이모지나 그림은 사용하지 마세요.\n",
    "    한국 고유의 표현을 사용하고,\n",
    "    은유와 상징을 통해 창의적으로 감정을 표현하세요.\n",
    "    시 해설은 필요 없습니다. 시만 작성하세요.\n",
    "    \n",
    "    ### 원문 텍스트:\n",
    "    {sample_text}\n",
    "    \n",
    "    ### 감정 목록:\n",
    "    {emotion}\n",
    "    \n",
    "    ### 시:\n",
    "    \"\"\"\n",
    "\n",
    "    # \"\"\" ### 시스템: 당신은 창의적이고 감성적인 근현대 시인입니다. 다음 감정목록에 언급된 감정들을 주된 시의 정서로 활용하세요. 영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요. 이모지나 그림을 사용하지 마세요. {context_snippets} 위 문장들에서 옛스러운 한국 고유의 표현을 사용하여 시를 하나 지어주세요. 은유와 상징을 사용하여 창의적으로 감정을 표현하세요. 시 해설은 필요없습니다. 시만 써주세요. 감정 목록: {top_emotion} ### 시: \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"emotion\"],\n",
    "        template=template.strip()\n",
    "    )\n",
    "    # print(emotion_scores)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = chain.run(sample_text=sample_text, emotion=emotion_scores)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6️⃣ 테스트\n",
    "generated_poem = emotion_to_poetry(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 시:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['아침 창가에 앉은 그대',\n",
       " '미풍이 살며시 불어오는 소리 들으며',\n",
       " '웃고 있는 내 마음 속 작은 꽃 하나',\n",
       " '',\n",
       " '어제보다 더 밝은 오늘이여',\n",
       " '그대가 내게 준 기쁨처럼',\n",
       " '햇살도 덩달아 춤추네',\n",
       " '',\n",
       " '꽃잎 사이 스며드는 바람결마다',\n",
       " '설레임 가득한 기다림 있어라',\n",
       " '희망이라는 이름의 푸른 날개짓',\n",
       " '',\n",
       " '내일이면 또 만날 수 있겠지',\n",
       " '그리운 눈빛 마주하며 웃을 그날까지',\n",
       " '가슴속 깊이 새긴 약속',\n",
       " '',\n",
       " '그대 향한 이 마음 끝닿도록',\n",
       " '영원히 이어질 우리 이야기여',\n",
       " '바람 따라 흐르는 행복 노래하리라']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"생성된 시:\\n\")\n",
    "extract_poetry_section(generated_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt-Based Poetry Generation 2\n",
    "Using Input Text and Emotion Classification Results (With a Vector Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Loading the Vector Store Built with the KcELECTRA Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KcELECTRA 기반 커스텀 임베딩 클래스 정의\n",
    "class KcELECTRAEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"beomi/KcELECTRA-base\", device: str = \"cpu\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def _embed(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        return [self._embed(text).tolist() for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        return self._embed(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff1ca1a64804091a38878f2b8f85de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03943e1771f74355bcd2cc27b96198d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/514 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce79be28742e4dd593dad66aa50771f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daf6e1d9cc8446d8aad521d291a99ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c1f8e5970a49de8888c02679d0f1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3️⃣ 벡터 임베딩 모델 로딩 (한국어 지원하는 모델 권장) KcElectra -> backbone 모델로 사용\n",
    "embedding_model = KcELECTRAEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에서 로드 (신뢰할 수 있는 파일일 경우)\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"./data/poetry_vectorstore\", #깃허브 파일은 링크 수정 \"./vectorstore\" 참고 - https://github.com/AKS-DHLAB/KPoEM/blob/main/KPoEM_vectorstore.ipynb\n",
    "    embedding_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - After Computing Vector Similarity, \n",
    "Use the Emotion Information Stored in the Metadata of the Retrieved 100 Entries to Construct Context for Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryGenerator:\n",
    "    \"\"\"감정 분석 + 문맥 검색 + 시 생성까지 전체 파이프라인을 수행하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, kpoem_model, vectorstore, llm):\n",
    "        \"\"\"\n",
    "        클래스 초기화\n",
    "        Args:\n",
    "            kpoem_model: KPoEM 감정 분류 모델\n",
    "            vectorstore: FAISS 등 벡터스토어 객체\n",
    "            llm: LangChain LLM 객체\n",
    "        \"\"\"\n",
    "        self.kpoem_model = kpoem_model\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "    # 상위 감정 리스트 반환\n",
    "    def get_top_emotions(self, scores, top_n=10):\n",
    "        \"\"\"점수 dict에서 상위 N개의 감정을 선택하고 key 리스트 반환\"\"\"\n",
    "        top_emotions = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n])\n",
    "        return top_emotions, list(top_emotions.keys())\n",
    "    # 상위 감정과 벡터DB의 메타데이터의 \"emotion\"값을 비교하여 가장 유사한 시구 10개를 선택\n",
    "    def filter_context_by_emotion(self, context, top_emotion_keys, top_k=10):\n",
    "        \"\"\"context(Document 리스트)에서 감정 교집합 개수로 필터링 및 정렬.\"\"\"\n",
    "        results_with_score = []\n",
    "        for doc in context:\n",
    "            doc_emotions = set(doc.metadata.get(\"emotion\", {}).keys())\n",
    "            overlap = doc_emotions.intersection(top_emotion_keys)\n",
    "            if overlap:\n",
    "                results_with_score.append((doc, len(overlap), overlap))\n",
    "        # 교집합 개수 많은 순으로 정렬 후 상위 top_k 선택\n",
    "        results_with_score.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, _, _ in results_with_score[:top_k]]\n",
    "\n",
    "    def build_prompt_template(self):\n",
    "        \"\"\"시 생성 프롬프트 템플릿 생성\"\"\"\n",
    "        return PromptTemplate(\n",
    "            input_variables=[\"top_emotion\", \"context_snippets\"],\n",
    "            template=\"\"\"\n",
    "            ### 시스템:\n",
    "            당신은 창의적이고 감성적인 근현대 시인입니다.  \n",
    "            아래에 제시된 원문 텍스트와 감정 목록을 참고하여 시를 지으세요.\n",
    "            원문 텍스트는 시의 소재나 분위기를 떠올리는 데 활용하고,\n",
    "            감정 목록에 언급된 감정들을 시의 핵심 정서로 반영하세요.  \n",
    "            영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요.  \n",
    "            이모지나 그림을 사용하지 마세요.  \n",
    "\n",
    "            아래에 제시된 참고 문장들에서 한국 고유의 표현을 사용하고,\n",
    "            은유와 상징을 통해 창의적으로 감정을 표현하세요.\n",
    "            시 해설은 필요 없습니다. 시만 작성하세요.\n",
    "            **원문 텍스트:**  \n",
    "            {sample_text}  \n",
    "\n",
    "            **참고 문장들:**  \n",
    "            {context_snippets}  \n",
    "\n",
    "            위 문장들을 바탕으로, 옛스러운 한국 고유의 표현을 사용하여 시를 하나 지어주세요.  \n",
    "            은유와 상징을 사용하여 창의적으로 감정을 표현하세요.  \n",
    "            시 해설은 필요없습니다. 시만 써주세요.  \n",
    "\n",
    "            **감정 목록:** {top_emotion}  \n",
    "\n",
    "            ### 시:\"\"\".strip()\n",
    "        )\n",
    "\n",
    "    def generate_poetry(self, user_input, top_n=10, context_k=100, filtered_k=10):\n",
    "        \"\"\"전체 파이프라인 실행: 감정 분석 → 문맥 검색 → 시 생성\"\"\"\n",
    "        # 1. 감정 분석\n",
    "        scores = self.kpoem_model.analyze(user_input, threshold=0.3) #인풋 텍스트 감정분류\n",
    "        top_emotions, top_emotion_keys = self.get_top_emotions(scores, top_n=top_n) #상위 감정 라벨 가져오기\n",
    "\n",
    "        # 2. 유사 문맥 검색\n",
    "        context = self.vectorstore.similarity_search(user_input, k=context_k) # 인풋 텍스트에 대한 벡터 유사도가 근접한 VecotreDB에 저장된 데이터 호출(100개로 세팅)\n",
    "        filtered_results = self.filter_context_by_emotion(context, top_emotion_keys, top_k=filtered_k) # 감정 값도 비슷한 백터유사도 근점 시구 필터링\n",
    "        print(\"검색된 감정유사한 벡터DB:\", filtered_results)\n",
    "        # 3. 문맥 텍스트 생성\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in filtered_results]) # 프롬프트엔지니어링에 사용할 문맥 텍스트 생성(RAG)\n",
    "        # print(context_text)\n",
    "        # 4. 프롬프트 생성 및 LLM 실행\n",
    "        prompt = self.build_prompt_template()\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        result = chain.run(sample_text=sample_text, top_emotion=top_emotions, context_snippets=context_text)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화\n",
    "generator = PoetryGenerator(kpoem_model=kpoem_model, vectorstore=vectorstore, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 실행\n",
    "user_text = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 감정유사한 벡터DB: [Document(id='e1bc9080-46f6-4be9-9a91-e06a5d53f800', metadata={'emotion': {'기대감': 1.0, '기쁨': 1.0, '깨달음': 0.6, '감동/감탄': 0.4, '행복': 0.4, '환영/호의': 0.2, '비장함': 0.2, '뿌듯함': 0.2, '편안/쾌적': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2}, 'poet': '김소월'}, page_content='그러하다, 봄날은 꿈꿀 때.'), Document(id='7c6e549f-a4f7-4a36-886d-f7a825875bbc', metadata={'emotion': {'기대감': 0.8, '뿌듯함': 0.6, '아껴주는': 0.6, '행복': 0.6, '기쁨': 0.6, '존경': 0.4, '즐거움/신남': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '안심/신뢰': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '고마움': 0.2, '우쭐댐/무시함': 0.2, '비장함': 0.2, '깨달음': 0.2}, 'poet': '한용운'}, page_content='가갸날을 자랑하겠습니다.'), Document(id='29604c36-ff2c-4e39-9d6f-8c6f144a12ef', metadata={'emotion': {'감동/감탄': 0.8, '고마움': 0.8, '기쁨': 0.8, '기대감': 0.4, '행복': 0.4, '환영/호의': 0.2, '존경': 0.2, '비장함': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2, '놀람': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='오오 은혜여, 살아있는 몸에는 넘치는 은혜여'), Document(id='d76edcb9-87d2-46c5-a37f-479bed21bbe9', metadata={'emotion': {'흐뭇함(귀여움/예쁨)': 1.0, '환영/호의': 0.6, '감동/감탄': 0.6, '기대감': 0.6, '아껴주는': 0.6, '고마움': 0.4, '기쁨': 0.4, '뿌듯함': 0.2, '편안/쾌적': 0.2, '신기함/관심': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2, '행복': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='상냥한 태양이 씻은듯한 얼굴로'), Document(id='848bf887-82b0-49c6-b387-794a014baeb0', metadata={'emotion': {'기대감': 0.8, '비장함': 0.6, '뿌듯함': 0.4, '기쁨': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2}, 'poet': '임화'}, page_content='홰보다도 밝게 타는 별이 되리라.'), Document(id='5dcb64d6-d4f6-4cb0-9577-e23182b2c147', metadata={'emotion': {'기쁨': 1.0, '감동/감탄': 0.8, '편안/쾌적': 0.8, '행복': 0.8, '즐거움/신남': 0.4, '환영/호의': 0.2, '기대감': 0.2, '신기함/관심': 0.2, '흐뭇함(귀여움/예쁨)': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='산뜻이 살에 숨는 바람이 좋기도 하다.'), Document(id='1d394e11-7c9c-4c57-b342-5f420f171253', metadata={'emotion': {'불쌍함/연민': 1.0, '존경': 0.6, '서러움': 0.6, '아껴주는': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '고마움': 0.2, '슬픔': 0.2, '기대감': 0.2, '안타까움/실망': 0.2, '비장함': 0.2, '뿌듯함': 0.2, '절망': 0.2, '깨달음': 0.2, '행복': 0.2, '기쁨': 0.2}, 'poet': '임화'}, page_content='주검까지도 사는 즐거움으로 부둥켜안은 청년의 아픈 행복을,'), Document(id='cfa2a87f-9acc-4028-a488-be285e6d0fef', metadata={'emotion': {'감동/감탄': 1.0, '신기함/관심': 0.6, '기쁨': 0.6, '편안/쾌적': 0.4, '아껴주는': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '행복': 0.4, '환영/호의': 0.2, '기대감': 0.2}, 'poet': '김소월'}, page_content='푸른 하늘은 고요히 내려 갈리던 그 보드러운 눈결!'), Document(id='ee6f633c-9ce2-4049-ac4a-c40775759821', metadata={'emotion': {'기대감': 1.0, '감동/감탄': 0.8, '기쁨': 0.8, '신기함/관심': 0.6, '즐거움/신남': 0.6, '뿌듯함': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '비장함': 0.2, '행복': 0.2}, 'poet': '임화'}, page_content='구름이 흐르는 곳으로 띄워볼까!'), Document(id='326ed004-31ce-4a8b-997d-e689a702b5bb', metadata={'emotion': {'감동/감탄': 0.8, '기대감': 0.8, '아껴주는': 0.8, '환영/호의': 0.4, '존경': 0.2, '비장함': 0.2, '흐뭇함(귀여움/예쁨)': 0.2, '기쁨': 0.2}, 'poet': '한용운'}, page_content='님이여 사랑이여 아침볕의 첫걸음이여')]\n",
      "### 시스템:\n",
      "            당신은 창의적이고 감성적인 근현대 시인입니다.  \n",
      "            아래에 제시된 원문 텍스트와 감정 목록을 참고하여 시를 지으세요.\n",
      "            원문 텍스트는 시의 소재나 분위기를 떠올리는 데 활용하고,\n",
      "            감정 목록에 언급된 감정들을 시의 핵심 정서로 반영하세요.  \n",
      "            영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요.  \n",
      "            이모지나 그림을 사용하지 마세요.  \n",
      "\n",
      "            아래에 제시된 참고 문장들에서 한국 고유의 표현을 사용하고,\n",
      "            은유와 상징을 통해 창의적으로 감정을 표현하세요.\n",
      "            시 해설은 필요 없습니다. 시만 작성하세요.\n",
      "            **원문 텍스트:**  \n",
      "            미풍에 웃는 아침을 기원하련다  \n",
      "\n",
      "            **참고 문장들:**  \n",
      "            그러하다, 봄날은 꿈꿀 때.\n",
      "가갸날을 자랑하겠습니다.\n",
      "오오 은혜여, 살아있는 몸에는 넘치는 은혜여\n",
      "상냥한 태양이 씻은듯한 얼굴로\n",
      "홰보다도 밝게 타는 별이 되리라.\n",
      "산뜻이 살에 숨는 바람이 좋기도 하다.\n",
      "주검까지도 사는 즐거움으로 부둥켜안은 청년의 아픈 행복을,\n",
      "푸른 하늘은 고요히 내려 갈리던 그 보드러운 눈결!\n",
      "구름이 흐르는 곳으로 띄워볼까!\n",
      "님이여 사랑이여 아침볕의 첫걸음이여  \n",
      "\n",
      "            위 문장들을 바탕으로, 옛스러운 한국 고유의 표현을 사용하여 시를 하나 지어주세요.  \n",
      "            은유와 상징을 사용하여 창의적으로 감정을 표현하세요.  \n",
      "            시 해설은 필요없습니다. 시만 써주세요.  \n",
      "\n",
      "            **감정 목록:** {'기대감': 0.919, '기쁨': 0.809, '즐거움/신남': 0.635, '행복': 0.622, '비장함': 0.511, '환영/호의': 0.496, '아껴주는': 0.372, '편안/쾌적': 0.32, '감동/감탄': 0.304}  \n",
      "\n",
      "            ### 시: \n",
      "            \n",
      "\n",
      "\n",
      "시 제목: 아침 미소\n",
      "\n",
      "미풍에 춤추는 꽃잎들이 웃음소리 내어라\n",
      "봄바람 타고 오는 설렘이 가슴 가득 차오르니\n",
      "아침 해가 솟아오르는 창가에 기대어 서서\n",
      "희망이란 이름의 씨앗을 마음 밭에 심는다\n",
      "\n",
      "그리움마저 곱게 다듬어진 이 새벽녘\n",
      "별빛 조각들이 눈물처럼 반짝이며 내려와\n",
      "살랑이는 산들바람 속에 묻혀버린 아픔도\n",
      "새로운 시작 앞에서 조용히 사라져간다\n",
      "\n",
      "청년 같은 열정으로 오늘 하루를 껴안고\n",
      "푸르른 하늘 바라보며 깊은 숨결 들이킨다\n",
      "삶이라는 바다 위에 띄우는 작은 배 한 척\n",
      "꿈과 현실 사이 어딘가를 향해 나아간다\n",
      "\n",
      "아아, 살아있다는 것 자체가 이토록 소중하니\n",
      "매 순간마다 새롭게 피어나는 기쁨이여\n",
      "어제의 상처들은 모두 추억이 되어가고\n",
      "내일의 희망은 더욱 선명하게 다가온다\n",
      "\n",
      "가슴속 깊이 새겨진 그리움의 흔적들\n",
      "모두 따뜻한 햇살 아래 녹아내리며\n",
      "오늘도 또 내일도 계속될 우리의 이야기\n",
      "그렇게 삶이라는 무대 위로 걸어 나간다\n"
     ]
    }
   ],
   "source": [
    "# 시 생성\n",
    "poem = generator.generate_poetry(user_text, top_n=10, context_k=100, filtered_k=10)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poem(text: str) -> str: \n",
    "    \"\"\" text에서 \"### 시:\" 이후 나오는 부분만 추출하고, 그 다음 섹션 마커(예: ### 전체:)가 나오면 그 앞까지만 반환. \"\"\" \n",
    "    start_marker = \"### 시:\" \n",
    "    end_markers = [\"### 전체:\", \"### 해설:\", \"### 요약:\"] # 필요한 경우 확장 가능 \n",
    "    if start_marker not in text: return \"[시를 찾을 수 없습니다]\" # 1) 시 시작 부분만 추출 \n",
    "    poem_section = text.split(start_marker, 1)[1].strip() # 2) 끝 마커가 있으면 그 앞까지만 자르기 \n",
    "    for end_marker in end_markers: \n",
    "        if end_marker in poem_section: \n",
    "            poem_section = poem_section.split(end_marker, 1)[0].strip() \n",
    "            break # 가장 먼저 등장한 마커까지만 사용 \n",
    "        return poem_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시 제목: 아침 미소\n",
      "\n",
      "미풍에 춤추는 꽃잎들이 웃음소리 내어라\n",
      "봄바람 타고 오는 설렘이 가슴 가득 차오르니\n",
      "아침 해가 솟아오르는 창가에 기대어 서서\n",
      "희망이란 이름의 씨앗을 마음 밭에 심는다\n",
      "\n",
      "그리움마저 곱게 다듬어진 이 새벽녘\n",
      "별빛 조각들이 눈물처럼 반짝이며 내려와\n",
      "살랑이는 산들바람 속에 묻혀버린 아픔도\n",
      "새로운 시작 앞에서 조용히 사라져간다\n",
      "\n",
      "청년 같은 열정으로 오늘 하루를 껴안고\n",
      "푸르른 하늘 바라보며 깊은 숨결 들이킨다\n",
      "삶이라는 바다 위에 띄우는 작은 배 한 척\n",
      "꿈과 현실 사이 어딘가를 향해 나아간다\n",
      "\n",
      "아아, 살아있다는 것 자체가 이토록 소중하니\n",
      "매 순간마다 새롭게 피어나는 기쁨이여\n",
      "어제의 상처들은 모두 추억이 되어가고\n",
      "내일의 희망은 더욱 선명하게 다가온다\n",
      "\n",
      "가슴속 깊이 새겨진 그리움의 흔적들\n",
      "모두 따뜻한 햇살 아래 녹아내리며\n",
      "오늘도 또 내일도 계속될 우리의 이야기\n",
      "그렇게 삶이라는 무대 위로 걸어 나간다\n"
     ]
    }
   ],
   "source": [
    "extracted_poem = extract_poem(poem)\n",
    "print(extracted_poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
