{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the KPoEM Dataset and Model: Poetry Generation\n",
    "\n",
    "- **KPpEM Emoiton Classification Medel** : AKS-DHLAB. (2025). KPoEM  [Computer software]. Hugging Face. https://doi.org/10.57967/hf/6301 \n",
    "- This code is uploaded in AKS-DHLAB. (2025). KPoEM [Computer software]. GitHub. https://github.com/AKS-DHLAB/KPoEM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic setup and library imports\n",
    "- Import Libraries and Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: faiss-cpu in /home/work/.local/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub langchain langchain-core langchain-community langchain-huggingface \n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, ElectraModel, AutoModelForCausalLM, pipeline\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the KPoEM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기초 세팅\n",
    "REPO_ID = \"AKS-DHLAB/KPoEM\" # 허깅페이스에 업로드된 감정분류모델 id\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #GPU 사용\n",
    "THRESH_HOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPoEM_Classifier 클래스\n",
    "class KPoEM_Classifier(nn.Module):\n",
    "    def __init__(self, repo_id, device):\n",
    "        self.labels = [\n",
    "            '불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경',\n",
    "            '기대감', '우쭐댐/무시함', '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적',\n",
    "            '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망', '한심함', '역겨움/징그러움',\n",
    "            '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음',\n",
    "            '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움',\n",
    "            '재미없음', '불쌍함/연민', '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰'\n",
    "        ]\n",
    "        num_labels = len(self.labels)\n",
    "        #모델 & 토크나이저 로드\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(repo_id) \n",
    "        self.electra = AutoModel.from_pretrained(repo_id)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.electra.config.hidden_size, num_labels)\n",
    "        )\n",
    "\n",
    "        weights_path = hf_hub_download(repo_id=repo_id, filename=\"classifier_state.bin\") #가중치 불러오기\n",
    "        self.classifier.load_state_dict(torch.load(weights_path, map_location=self.device))\n",
    "        self.to(self.device)\n",
    "        self.eval()\n",
    "\n",
    "    # 텍스트를 입력받아 최종 logits 반환\n",
    "    def forward(self, text: str):\n",
    "        encoding = self.tokenizer(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=512,\n",
    "          padding=\"max_length\",\n",
    "          truncation=True,\n",
    "          return_tensors='pt',\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.electra(\n",
    "                input_ids=encoding[\"input_ids\"],\n",
    "                attention_mask=encoding[\"attention_mask\"],\n",
    "                token_type_ids=encoding[\"token_type_ids\"]\n",
    "            )\n",
    "\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    def analyze(self, text: str, threshold=0):\n",
    "        logits = self.forward(text)\n",
    "        probabilities = torch.sigmoid(logits.squeeze()) #확률로 변환 → threshold 이상이면 선택\n",
    "        predictions = (probabilities > threshold).int()\n",
    "\n",
    "        result_dict = {\n",
    "            self.labels[i]: float(round(probabilities[i].item(), 3))\n",
    "            for i, label_id in enumerate(predictions)\n",
    "            if label_id == 1\n",
    "        }\n",
    "\n",
    "        # 확률값 기준 내림차순 정렬된 dict로 반환\n",
    "        result_dict = dict(sorted(result_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "        return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 'cuda' 환경에서 'AKS-DHLAB/KPoEM' 모델을 로드하고 있습니다 ...\n",
      "KPoEM 모델을 성공적으로 로드하였습니다.\n"
     ]
    }
   ],
   "source": [
    "# KPoEM 모델 로드\n",
    "print(f\"... '{DEVICE}' 환경에서 '{REPO_ID}' 모델을 로드하고 있습니다 ...\")\n",
    "kpoem_model = KPoEM_Classifier(repo_id=REPO_ID, device=DEVICE)\n",
    "print(\"KPoEM 모델을 성공적으로 로드하였습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'기대감': 0.919,\n",
       " '기쁨': 0.809,\n",
       " '즐거움/신남': 0.635,\n",
       " '행복': 0.622,\n",
       " '비장함': 0.511,\n",
       " '환영/호의': 0.495,\n",
       " '아껴주는': 0.372,\n",
       " '편안/쾌적': 0.32,\n",
       " '감동/감탄': 0.304}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 테스트\n",
    "test = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\"\n",
    "result = kpoem_model.analyze(test, threshold=THRESH_HOLD)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downloading and Loading the LLM for Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad109e5a38f421ebb9d90d69109d23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b235b4a24ba140fe984767ae0b9c63c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbc9dcc54c749369a6c943c5918f5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f06148088a40edbfebfddc969a6cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료. GPU/CPU 자동 오프로딩 활성화\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_883/3750988198.py:31: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n",
      "/tmp/ipykernel_883/3750988198.py:40: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"K-intelligence/Midm-2.0-Base-Instruct\"\n",
    "CACHE_DIR = \"/home/work/KPoEM/code/AICreation/model\"\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "#모델 로드 - device_map=\"auto\" 유지 (자동 분산 로드)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",           # GPU + CPU 메모리 자동 분산\n",
    "    low_cpu_mem_usage=True,      # 로딩 시 CPU 메모리 절약\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "print(\"모델 로드 완료. GPU/CPU 자동 오프로딩 활성화\")\n",
    "\n",
    "# HuggingFace pipeline 생성 (device 설정하지 않아도 자동)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=512,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "# LangChain LLM 래퍼로 감싸기\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 간단한 프롬프트 템플릿\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"다음 주제로 감성적인 시를 써주세요:\\n주제: {topic}\\n\\n### 시:\\n\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt-Based Poetry Generation 1\n",
    "Using Input Text and Emotion Classification Results (Without a Vector Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 감정 분류 모델만 적용하여 LLM으로 시 생성(Vector DB 미적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poetry_section(template):\n",
    "    # Split the template by \"### 시:\" and extract the part after it\n",
    "    if \"### 시:\" in template:\n",
    "        poetry_section = template.split(\"### 시:\")[1].strip()\n",
    "        # Split by lines and return as a list\n",
    "        poetry_lines = poetry_section.splitlines()\n",
    "        return poetry_lines\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ 전체 흐름 함수\n",
    "def emotion_to_poetry(sample_text): #감정 분류에 사용할 사용자 텍스트 인풋.\n",
    "    emotion_scores = kpoem_model.analyze(sample_text, threshold=0.3)\n",
    "    \n",
    "    template = \"\"\"\n",
    "    ### 시스템:\n",
    "    당신은 창의적이고 감성적인 근현대 시인입니다.\n",
    "    다음 감정목록에 언급된 감정들을 주된 시의 정서로 활용하세요.\n",
    "    영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요.\n",
    "    이모지나 그림을 사용하지 마세요.\n",
    "    한국 고유의 표현을 사용하여 시를 하나 지어주세요.\n",
    "    은유와 상징을 사용하여 창의적으로 감정을 표현하세요.\n",
    "    시 해설은 필요없습니다. 시만 써주세요.\n",
    "    \n",
    "    생성한 시만 알려주세요. 그 외에 설명은 포함하지 마세요.\n",
    "    ### 감정 목록: {emotion}\n",
    "    ### 시:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"emotion\"],\n",
    "        template=template.strip()\n",
    "    )\n",
    "    # print(emotion_scores)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    result = chain.run(emotion=emotion_scores)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6️⃣ 테스트\n",
    "generated_poem = emotion_to_poetry(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 시:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['달맞이꽃 피어나는 저녁',\n",
       " '바람결 따라 춤추는 꽃잎들 사이로',\n",
       " '그대 마음도 함께 춤추네',\n",
       " '',\n",
       " '달빛이 속삭이는 밤길에서',\n",
       " '작은 별들이 손 흔들며 반기니',\n",
       " '내 가슴 속 설렘도 춤춘다',\n",
       " '',\n",
       " '봄날 같은 그대 눈빛에',\n",
       " '희망이라는 꽃봉오리가 피고',\n",
       " '기다림 끝 찾아온 반가움이여',\n",
       " '',\n",
       " '가슴 깊이 새겨진 그리움처럼',\n",
       " '사랑이란 이름의 씨앗 뿌려지니',\n",
       " '하늘 높이 날아오르는 기쁨이라']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"생성된 시:\\n\")\n",
    "extract_poetry_section(generated_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prompt-Based Poetry Generation 2\n",
    "Using Input Text and Emotion Classification Results (With a Vector Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Loading the Vector Store Built with the KcELECTRA Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KcELECTRA 기반 커스텀 임베딩 클래스 정의\n",
    "class KcELECTRAEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"beomi/KcELECTRA-base\", device: str = \"cpu\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def _embed(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        return [self._embed(text).tolist() for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        return self._embed(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d0b18f882b4e65bc02f3a5414cc883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f307e7c3a764a9199ec0d00ee9080d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/514 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13605e4f83f841e9812903e15405b616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb8b3482fe645139d4b8aecfbef9d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf4d9d27f8d4a729b98de0502527ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3️⃣ 벡터 임베딩 모델 로딩 (한국어 지원하는 모델 권장) KcElectra -> backbone 모델로 사용\n",
    "embedding_model = KcELECTRAEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에서 로드 (신뢰할 수 있는 파일일 경우)\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"./data/poetry_vectorstore\", #깃허브 파일은 링크 수정 \"./vectorstore\" 참고 - https://github.com/AKS-DHLAB/KPoEM/blob/main/KPoEM_vectorstore.ipynb\n",
    "    embedding_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - After Computing Vector Similarity, \n",
    "Use the Emotion Information Stored in the Metadata of the Retrieved 100 Entries to Construct Context for Poetry Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryGenerator:\n",
    "    \"\"\"감정 분석 + 문맥 검색 + 시 생성까지 전체 파이프라인을 수행하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, kpoem_model, vectorstore, llm):\n",
    "        \"\"\"\n",
    "        클래스 초기화\n",
    "        Args:\n",
    "            kpoem_model: KPoEM 감정 분류 모델\n",
    "            vectorstore: FAISS 등 벡터스토어 객체\n",
    "            llm: LangChain LLM 객체\n",
    "        \"\"\"\n",
    "        self.kpoem_model = kpoem_model\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "    # 상위 감정 리스트 반환\n",
    "    def get_top_emotions(self, scores, top_n=10):\n",
    "        \"\"\"점수 dict에서 상위 N개의 감정을 선택하고 key 리스트 반환\"\"\"\n",
    "        top_emotions = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n])\n",
    "        return top_emotions, list(top_emotions.keys())\n",
    "    # 상위 감정과 벡터DB의 메타데이터의 \"emotion\"값을 비교하여 가장 유사한 시구 10개를 선택\n",
    "    def filter_context_by_emotion(self, context, top_emotion_keys, top_k=10):\n",
    "        \"\"\"context(Document 리스트)에서 감정 교집합 개수로 필터링 및 정렬.\"\"\"\n",
    "        results_with_score = []\n",
    "        for doc in context:\n",
    "            doc_emotions = set(doc.metadata.get(\"emotion\", {}).keys())\n",
    "            overlap = doc_emotions.intersection(top_emotion_keys)\n",
    "            if overlap:\n",
    "                results_with_score.append((doc, len(overlap), overlap))\n",
    "        # 교집합 개수 많은 순으로 정렬 후 상위 top_k 선택\n",
    "        results_with_score.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, _, _ in results_with_score[:top_k]]\n",
    "\n",
    "    def build_prompt_template(self):\n",
    "        \"\"\"시 생성 프롬프트 템플릿 생성\"\"\"\n",
    "        return PromptTemplate(\n",
    "            input_variables=[\"top_emotion\", \"context_snippets\"],\n",
    "            template=\"\"\"\n",
    "            ### 시스템:\n",
    "            당신은 창의적이고 감성적인 근현대 시인입니다. \n",
    "            다음 감정목록에 언급된 감정들을 주된 시의 정서로 활용하세요.\n",
    "            영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요. \n",
    "            이모지나 그림을 사용하지 마세요.\n",
    "            {context_snippets} \n",
    "            위 문장들에서 옛스러운 한국 고유의 표현을 사용하여 시를 하나 지어주세요.\n",
    "            은유와 상징을 사용하여 창의적으로 감정을 표현하세요. \n",
    "            시 해설은 필요없습니다. 시만 써주세요.\n",
    "            감정 목록: {top_emotion}\n",
    "            ### 시:\n",
    "            \"\"\".strip()\n",
    "        )\n",
    "\n",
    "    def generate_poetry(self, user_input, top_n=10, context_k=100, filtered_k=10):\n",
    "        \"\"\"전체 파이프라인 실행: 감정 분석 → 문맥 검색 → 시 생성\"\"\"\n",
    "        # 1. 감정 분석\n",
    "        scores = self.kpoem_model.analyze(user_input, threshold=0.3) #인풋 텍스트 감정분류\n",
    "        top_emotions, top_emotion_keys = self.get_top_emotions(scores, top_n=top_n) #상위 감정 라벨 가져오기\n",
    "\n",
    "        # 2. 유사 문맥 검색\n",
    "        context = self.vectorstore.similarity_search(user_input, k=context_k) # 인풋 텍스트에 대한 벡터 유사도가 근접한 VecotreDB에 저장된 데이터 호출(100개로 세팅)\n",
    "        filtered_results = self.filter_context_by_emotion(context, top_emotion_keys, top_k=filtered_k) # 감정 값도 비슷한 백터유사도 근점 시구 필터링\n",
    "        print(\"검색된 감정유사한 벡터DB:\", filtered_results)\n",
    "        # 3. 문맥 텍스트 생성\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in filtered_results]) # 프롬프트엔지니어링에 사용할 문맥 텍스트 생성(RAG)\n",
    "        # print(context_text)\n",
    "        # 4. 프롬프트 생성 및 LLM 실행\n",
    "        prompt = self.build_prompt_template()\n",
    "        chain = LLMChain(llm=self.llm, prompt=prompt)\n",
    "        result = chain.run(top_emotion=top_emotions, context_snippets=context_text)\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화\n",
    "generator = PoetryGenerator(kpoem_model=kpoem_model, vectorstore=vectorstore, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 실행\n",
    "user_text = \"\"\"미풍에 웃는 아침을 기원하련다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 감정유사한 벡터DB: [Document(id='e1bc9080-46f6-4be9-9a91-e06a5d53f800', metadata={'emotion': {'기대감': 1.0, '기쁨': 1.0, '깨달음': 0.6, '감동/감탄': 0.4, '행복': 0.4, '환영/호의': 0.2, '비장함': 0.2, '뿌듯함': 0.2, '편안/쾌적': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2}, 'poet': '김소월'}, page_content='그러하다, 봄날은 꿈꿀 때.'), Document(id='7c6e549f-a4f7-4a36-886d-f7a825875bbc', metadata={'emotion': {'기대감': 0.8, '뿌듯함': 0.6, '아껴주는': 0.6, '행복': 0.6, '기쁨': 0.6, '존경': 0.4, '즐거움/신남': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '안심/신뢰': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '고마움': 0.2, '우쭐댐/무시함': 0.2, '비장함': 0.2, '깨달음': 0.2}, 'poet': '한용운'}, page_content='가갸날을 자랑하겠습니다.'), Document(id='29604c36-ff2c-4e39-9d6f-8c6f144a12ef', metadata={'emotion': {'감동/감탄': 0.8, '고마움': 0.8, '기쁨': 0.8, '기대감': 0.4, '행복': 0.4, '환영/호의': 0.2, '존경': 0.2, '비장함': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2, '놀람': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='오오 은혜여, 살아있는 몸에는 넘치는 은혜여'), Document(id='d76edcb9-87d2-46c5-a37f-479bed21bbe9', metadata={'emotion': {'흐뭇함(귀여움/예쁨)': 1.0, '환영/호의': 0.6, '감동/감탄': 0.6, '기대감': 0.6, '아껴주는': 0.6, '고마움': 0.4, '기쁨': 0.4, '뿌듯함': 0.2, '편안/쾌적': 0.2, '신기함/관심': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2, '행복': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='상냥한 태양이 씻은듯한 얼굴로'), Document(id='848bf887-82b0-49c6-b387-794a014baeb0', metadata={'emotion': {'기대감': 0.8, '비장함': 0.6, '뿌듯함': 0.4, '기쁨': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '아껴주는': 0.2, '즐거움/신남': 0.2, '깨달음': 0.2}, 'poet': '임화'}, page_content='홰보다도 밝게 타는 별이 되리라.'), Document(id='5dcb64d6-d4f6-4cb0-9577-e23182b2c147', metadata={'emotion': {'기쁨': 1.0, '감동/감탄': 0.8, '편안/쾌적': 0.8, '행복': 0.8, '즐거움/신남': 0.4, '환영/호의': 0.2, '기대감': 0.2, '신기함/관심': 0.2, '흐뭇함(귀여움/예쁨)': 0.2, '안심/신뢰': 0.2}, 'poet': '김소월'}, page_content='산뜻이 살에 숨는 바람이 좋기도 하다.'), Document(id='1d394e11-7c9c-4c57-b342-5f420f171253', metadata={'emotion': {'불쌍함/연민': 1.0, '존경': 0.6, '서러움': 0.6, '아껴주는': 0.4, '환영/호의': 0.2, '감동/감탄': 0.2, '고마움': 0.2, '슬픔': 0.2, '기대감': 0.2, '안타까움/실망': 0.2, '비장함': 0.2, '뿌듯함': 0.2, '절망': 0.2, '깨달음': 0.2, '행복': 0.2, '기쁨': 0.2}, 'poet': '임화'}, page_content='주검까지도 사는 즐거움으로 부둥켜안은 청년의 아픈 행복을,'), Document(id='cfa2a87f-9acc-4028-a488-be285e6d0fef', metadata={'emotion': {'감동/감탄': 1.0, '신기함/관심': 0.6, '기쁨': 0.6, '편안/쾌적': 0.4, '아껴주는': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '행복': 0.4, '환영/호의': 0.2, '기대감': 0.2}, 'poet': '김소월'}, page_content='푸른 하늘은 고요히 내려 갈리던 그 보드러운 눈결!'), Document(id='ee6f633c-9ce2-4049-ac4a-c40775759821', metadata={'emotion': {'기대감': 1.0, '감동/감탄': 0.8, '기쁨': 0.8, '신기함/관심': 0.6, '즐거움/신남': 0.6, '뿌듯함': 0.4, '흐뭇함(귀여움/예쁨)': 0.4, '비장함': 0.2, '행복': 0.2}, 'poet': '임화'}, page_content='구름이 흐르는 곳으로 띄워볼까!'), Document(id='326ed004-31ce-4a8b-997d-e689a702b5bb', metadata={'emotion': {'감동/감탄': 0.8, '기대감': 0.8, '아껴주는': 0.8, '환영/호의': 0.4, '존경': 0.2, '비장함': 0.2, '흐뭇함(귀여움/예쁨)': 0.2, '기쁨': 0.2}, 'poet': '한용운'}, page_content='님이여 사랑이여 아침볕의 첫걸음이여')]\n",
      "### 시스템:\n",
      "            당신은 창의적이고 감성적인 근현대 시인입니다. \n",
      "            다음 감정목록에 언급된 감정들을 주된 시의 정서로 활용하세요.\n",
      "            영어나 다른 언어는 사용하지 말고, 한국어로만 작성하세요. \n",
      "            이모지나 그림을 사용하지 마세요.\n",
      "            그러하다, 봄날은 꿈꿀 때.\n",
      "가갸날을 자랑하겠습니다.\n",
      "오오 은혜여, 살아있는 몸에는 넘치는 은혜여\n",
      "상냥한 태양이 씻은듯한 얼굴로\n",
      "홰보다도 밝게 타는 별이 되리라.\n",
      "산뜻이 살에 숨는 바람이 좋기도 하다.\n",
      "주검까지도 사는 즐거움으로 부둥켜안은 청년의 아픈 행복을,\n",
      "푸른 하늘은 고요히 내려 갈리던 그 보드러운 눈결!\n",
      "구름이 흐르는 곳으로 띄워볼까!\n",
      "님이여 사랑이여 아침볕의 첫걸음이여 \n",
      "            위 문장들에서 옛스러운 한국 고유의 표현을 사용하여 시를 하나 지어주세요.\n",
      "            은유와 상징을 사용하여 창의적으로 감정을 표현하세요. \n",
      "            시 해설은 필요없습니다. 시만 써주세요.\n",
      "            감정 목록: {'기대감': 0.919, '기쁨': 0.809, '즐거움/신남': 0.635, '행복': 0.622, '비장함': 0.511, '환영/호의': 0.495, '아껴주는': 0.372, '편안/쾌적': 0.32, '감동/감탄': 0.304}\n",
      "            ### 시: \n",
      "\n",
      "아아 그리운 날들이여, 다시 찾아온 봄빛 속에서\n",
      "나의 마음 밭에도 새싹이 돋아나네\n",
      "따스한 햇살 한 줌 가슴 가득 품어보니\n",
      "꿈틀대는 생명의 숨결이 온몸을 감싸누나\n",
      "\n",
      "꽃잎처럼 흩어지는 그리움의 조각들\n",
      "그 사이사이 스며드는 설렘과 기쁨이여\n",
      "아침이슬 맺힌 풀잎마저 춤추는 이 순간\n",
      "살아있음 자체가 축복이라 노래하네\n",
      "\n",
      "그리운 님이시여, 나의 모든 것을 바쳐도\n",
      "당신 향한 마음은 더욱 깊어져 가노라\n",
      "별빛 같은 눈동자에 담긴 끝없는 갈망\n",
      "봄바람 타고 흘러가는 영원한 약속이여\n",
      "\n",
      "사랑한다는 말조차 부족한 이 벅찬 감동\n",
      "가슴속 깊이 새겨진 당신의 흔적 따라\n",
      "오늘도 내일도 영원히 함께하리\n",
      "우리 두 사람만의 소중한 시간 만들어가리\n"
     ]
    }
   ],
   "source": [
    "# 시 생성\n",
    "poem = generator.generate_poetry(user_text, top_n=10, context_k=100, filtered_k=10)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poem(text: str) -> str: \n",
    "    \"\"\" text에서 \"### 시:\" 이후 나오는 부분만 추출하고, 그 다음 섹션 마커(예: ### 전체:)가 나오면 그 앞까지만 반환. \"\"\" \n",
    "    start_marker = \"### 시:\" \n",
    "    end_markers = [\"### 전체:\", \"### 해설:\", \"### 요약:\"] # 필요한 경우 확장 가능 \n",
    "    if start_marker not in text: return \"[시를 찾을 수 없습니다]\" # 1) 시 시작 부분만 추출 \n",
    "    poem_section = text.split(start_marker, 1)[1].strip() # 2) 끝 마커가 있으면 그 앞까지만 자르기 \n",
    "    for end_marker in end_markers: \n",
    "        if end_marker in poem_section: \n",
    "            poem_section = poem_section.split(end_marker, 1)[0].strip() \n",
    "            break # 가장 먼저 등장한 마커까지만 사용 \n",
    "        return poem_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아아 그리운 날들이여, 다시 찾아온 봄빛 속에서\n",
      "나의 마음 밭에도 새싹이 돋아나네\n",
      "따스한 햇살 한 줌 가슴 가득 품어보니\n",
      "꿈틀대는 생명의 숨결이 온몸을 감싸누나\n",
      "\n",
      "꽃잎처럼 흩어지는 그리움의 조각들\n",
      "그 사이사이 스며드는 설렘과 기쁨이여\n",
      "아침이슬 맺힌 풀잎마저 춤추는 이 순간\n",
      "살아있음 자체가 축복이라 노래하네\n",
      "\n",
      "그리운 님이시여, 나의 모든 것을 바쳐도\n",
      "당신 향한 마음은 더욱 깊어져 가노라\n",
      "별빛 같은 눈동자에 담긴 끝없는 갈망\n",
      "봄바람 타고 흘러가는 영원한 약속이여\n",
      "\n",
      "사랑한다는 말조차 부족한 이 벅찬 감동\n",
      "가슴속 깊이 새겨진 당신의 흔적 따라\n",
      "오늘도 내일도 영원히 함께하리\n",
      "우리 두 사람만의 소중한 시간 만들어가리\n"
     ]
    }
   ],
   "source": [
    "extracted_poem = extract_poem(poem)\n",
    "print(extracted_poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
